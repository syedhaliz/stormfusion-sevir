{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4: Perceptual Loss Lambda Sweep\n",
    "\n",
    "**READY TO RUN**: Just click Runtime → Run All\n",
    "\n",
    "This notebook:\n",
    "1. Sets up environment (GPU, packages)\n",
    "2. Mounts Google Drive for data access\n",
    "3. Installs StormFusion code\n",
    "4. Runs λ sweep: {0.0001, 0.0005, 0.001}\n",
    "5. Compares results\n",
    "6. Saves checkpoints to Drive\n",
    "\n",
    "**Expected time:** 20-30 minutes on L4/A100 GPU\n",
    "\n",
    "**Success criteria:**\n",
    "- ✅ CSI@74 ≥ 0.65 (maintains forecast skill)\n",
    "- ✅ LPIPS < 0.35 (improves sharpness)\n",
    "\n",
    "**See:** `docs/WHY_PERCEPTUAL_LOSS_MATTERS.md` for context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠️  WARNING: No GPU detected. Training will be VERY slow.\")\n",
    "    print(\"   Go to Runtime → Change runtime type → Select GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision h5py pandas tqdm pyyaml lpips scikit-image\n",
    "print(\"✅ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify data exists\n",
    "import os\n",
    "data_root = '/content/drive/MyDrive/SEVIR_Data'\n",
    "if os.path.exists(data_root):\n",
    "    print(f\"✅ Data found at {data_root}\")\n",
    "    !ls -lh {data_root}\n",
    "else:\n",
    "    print(f\"❌ Data not found at {data_root}\")\n",
    "    print(\"   Please ensure SEVIR data is uploaded to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Install StormFusion Code\n",
    "\n",
    "**Option A:** Upload from local machine  \n",
    "**Option B:** Clone from git (if you pushed to GitHub)  \n",
    "**Option C:** Install files manually (implemented below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory structure\n",
    "!mkdir -p stormfusion/data\n",
    "!mkdir -p stormfusion/models/losses\n",
    "!mkdir -p stormfusion/training\n",
    "!mkdir -p stormfusion/models/layers\n",
    "!mkdir -p outputs/checkpoints\n",
    "!mkdir -p outputs/logs\n",
    "!mkdir -p data/samples\n",
    "\n",
    "# Create __init__.py files\n",
    "!touch stormfusion/__init__.py\n",
    "!touch stormfusion/data/__init__.py\n",
    "!touch stormfusion/models/__init__.py\n",
    "!touch stormfusion/models/layers/__init__.py\n",
    "!touch stormfusion/training/__init__.py\n",
    "\n",
    "print(\"✅ Directory structure created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📤 UPLOAD REQUIRED FILES\n",
    "\n",
    "**Please upload these files from your local machine:**\n",
    "\n",
    "1. `stormfusion/data/sevir_dataset.py`\n",
    "2. `stormfusion/models/unet2d.py`\n",
    "3. `stormfusion/models/layers/conv_blocks.py`\n",
    "4. `stormfusion/models/losses/vgg_perceptual.py`\n",
    "5. `stormfusion/models/losses/__init__.py`\n",
    "6. `stormfusion/training/metrics.py`\n",
    "7. `stormfusion/training/forecast_metrics.py`\n",
    "8. `scripts/train_unet_with_perceptual.py`\n",
    "9. `data/samples/tiny_train_ids.txt`\n",
    "10. `data/samples/tiny_val_ids.txt`\n",
    "\n",
    "**Run the cell below to upload files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "print(\"Upload files one by one (or use Drive if already uploaded)\")\n",
    "print(\"\\nAfter uploading, manually move them to correct locations.\")\n",
    "print(\"\\nAlternatively, upload entire stormfusion-sevir folder to Drive and:\")\n",
    "print(\"  !cp -r /content/drive/MyDrive/stormfusion-sevir/* .\")\n",
    "\n",
    "# Uncomment if you uploaded to Drive:\n",
    "# !cp -r /content/drive/MyDrive/stormfusion-sevir/stormfusion ./\n",
    "# !cp -r /content/drive/MyDrive/stormfusion-sevir/scripts ./\n",
    "# !cp -r /content/drive/MyDrive/stormfusion-sevir/data/samples ./data/\n",
    "# print(\"✅ Files copied from Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Quick Copy from Drive\n",
    "\n",
    "**If you uploaded the entire project to Drive:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and modify path if needed:\n",
    "# !cp -r /content/drive/MyDrive/stormfusion-sevir/stormfusion ./\n",
    "# !cp -r /content/drive/MyDrive/stormfusion-sevir/scripts ./\n",
    "# !cp -r /content/drive/MyDrive/stormfusion-sevir/data ./\n",
    "# print(\"✅ Project copied from Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports\n",
    "try:\n",
    "    from stormfusion.data.sevir_dataset import build_tiny_index, SevirNowcastDataset\n",
    "    from stormfusion.models.unet2d import UNet2D\n",
    "    from stormfusion.models.losses import VGGPerceptualLoss\n",
    "    from stormfusion.training.metrics import mse, lpips_metric\n",
    "    from stormfusion.training.forecast_metrics import scores\n",
    "    print(\"✅ All imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import failed: {e}\")\n",
    "    print(\"   Please upload missing files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link SEVIR data from Drive\n",
    "!ln -sf /content/drive/MyDrive/SEVIR_Data/SEVIR_CATALOG.csv data/SEVIR_CATALOG.csv\n",
    "!ln -sf /content/drive/MyDrive/SEVIR_Data/sevir data/sevir\n",
    "\n",
    "# Verify\n",
    "!ls -lh data/\n",
    "print(\"\\n✅ Data paths configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Lambda Sweep Training\n",
    "\n",
    "**We'll train 3 models with different λ values:**\n",
    "- λ = 0.0001 (conservative: minimal perceptual)\n",
    "- λ = 0.0005 (balanced: recommended)\n",
    "- λ = 0.001 (aggressive: maximum sharpness)\n",
    "\n",
    "**Each training takes ~5-10 minutes on GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Lambda values to test\n",
    "lambdas = [0.0001, 0.0005, 0.001]\n",
    "results_summary = {}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for lambda_val in lambdas:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"TRAINING WITH LAMBDA = {lambda_val}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    run_start = time.time()\n",
    "    \n",
    "    # Run training\n",
    "    !python scripts/train_unet_with_perceptual.py \\\n",
    "        --lambda_perc {lambda_val} \\\n",
    "        --epochs 10 \\\n",
    "        --run_name lambda{lambda_val}\n",
    "    \n",
    "    run_time = time.time() - run_start\n",
    "    \n",
    "    # Load results\n",
    "    history_file = f'outputs/checkpoints/unet_perceptual_lambda{lambda_val}_history.json'\n",
    "    try:\n",
    "        with open(history_file) as f:\n",
    "            hist = json.load(f)\n",
    "        \n",
    "        best_csi = max(hist['val_csi_74'])\n",
    "        best_lpips = min(hist['val_lpips'])\n",
    "        best_mse = min(hist['val_mse'])\n",
    "        \n",
    "        results_summary[lambda_val] = {\n",
    "            'csi': best_csi,\n",
    "            'lpips': best_lpips,\n",
    "            'mse': best_mse,\n",
    "            'time': run_time\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n✅ Lambda {lambda_val} completed in {run_time/60:.1f} minutes\")\n",
    "        print(f\"   CSI@74: {best_csi:.3f}\")\n",
    "        print(f\"   LPIPS:  {best_lpips:.3f}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n❌ Lambda {lambda_val} failed - history file not found\")\n",
    "        results_summary[lambda_val] = {'error': 'Training failed'}\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"TOTAL TIME: {total_time/60:.1f} minutes\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LAMBDA SWEEP RESULTS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Baseline for comparison\n",
    "baseline_csi = 0.68\n",
    "baseline_lpips = 0.40\n",
    "\n",
    "print(f\"Baseline (MSE only):\")\n",
    "print(f\"  CSI@74: {baseline_csi:.3f}\")\n",
    "print(f\"  LPIPS:  {baseline_lpips:.3f}\")\n",
    "print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "\n",
    "best_lambda = None\n",
    "best_score = -1\n",
    "\n",
    "for lambda_val in lambdas:\n",
    "    if 'error' in results_summary[lambda_val]:\n",
    "        print(f\"Lambda = {lambda_val}: FAILED\")\n",
    "        continue\n",
    "    \n",
    "    res = results_summary[lambda_val]\n",
    "    csi = res['csi']\n",
    "    lpips = res['lpips']\n",
    "    mse = res['mse']\n",
    "    \n",
    "    # Check success criteria\n",
    "    csi_pass = csi >= 0.65\n",
    "    lpips_pass = lpips < 0.35\n",
    "    success = csi_pass and lpips_pass\n",
    "    \n",
    "    # Calculate improvement\n",
    "    csi_change = ((csi - baseline_csi) / baseline_csi) * 100\n",
    "    lpips_change = ((lpips - baseline_lpips) / baseline_lpips) * 100\n",
    "    \n",
    "    print(f\"Lambda = {lambda_val}:\")\n",
    "    print(f\"  CSI@74:  {csi:.3f} {'✅' if csi_pass else '❌'} ({csi_change:+.1f}% vs baseline)\")\n",
    "    print(f\"  LPIPS:   {lpips:.3f} {'✅' if lpips_pass else '❌'} ({lpips_change:+.1f}% vs baseline)\")\n",
    "    print(f\"  Val MSE: {mse:.4f}\")\n",
    "    print(f\"  SUCCESS: {'YES ✅✅✅' if success else 'NO ❌'}\")\n",
    "    print(f\"  Time:    {res['time']/60:.1f} min\")\n",
    "    print()\n",
    "    \n",
    "    # Track best (prioritize CSI, then LPIPS)\n",
    "    if success and csi > best_score:\n",
    "        best_score = csi\n",
    "        best_lambda = lambda_val\n",
    "\n",
    "print(\"-\"*80)\n",
    "if best_lambda is not None:\n",
    "    print(f\"\\n🎉 BEST LAMBDA: {best_lambda}\")\n",
    "    print(f\"   CSI@74: {results_summary[best_lambda]['csi']:.3f}\")\n",
    "    print(f\"   LPIPS:  {results_summary[best_lambda]['lpips']:.3f}\")\n",
    "    print(f\"\\n✅ Stage 4 SUCCESS! Use lambda={best_lambda} for Stage 5.\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  No lambda met both criteria.\")\n",
    "    print(f\"   Check individual results above.\")\n",
    "    print(f\"   May need to adjust lambda range or accept partial success.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Visualize Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "colors = {'0.0001': 'blue', '0.0005': 'green', '0.001': 'red'}\n",
    "baseline_csi = 0.68\n",
    "baseline_lpips = 0.40\n",
    "\n",
    "for lambda_val in lambdas:\n",
    "    history_file = f'outputs/checkpoints/unet_perceptual_lambda{lambda_val}_history.json'\n",
    "    try:\n",
    "        with open(history_file) as f:\n",
    "            hist = json.load(f)\n",
    "        \n",
    "        color = colors[str(lambda_val)]\n",
    "        epochs = range(1, len(hist['val_csi_74']) + 1)\n",
    "        \n",
    "        # Plot 1: Training loss\n",
    "        axes[0, 0].plot(epochs, hist['train_mse_loss'], label=f'λ={lambda_val}', color=color)\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Train MSE')\n",
    "        axes[0, 0].set_title('Training MSE Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Val MSE\n",
    "        axes[0, 1].plot(epochs, hist['val_mse'], label=f'λ={lambda_val}', color=color)\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Val MSE')\n",
    "        axes[0, 1].set_title('Validation MSE')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: CSI@74\n",
    "        axes[1, 0].plot(epochs, hist['val_csi_74'], label=f'λ={lambda_val}', color=color, linewidth=2)\n",
    "        \n",
    "        # Plot 4: LPIPS\n",
    "        axes[1, 1].plot(epochs, hist['val_lpips'], label=f'λ={lambda_val}', color=color, linewidth=2)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Could not plot lambda={lambda_val} - file not found\")\n",
    "\n",
    "# Add baselines and thresholds\n",
    "axes[1, 0].axhline(y=baseline_csi, color='black', linestyle='--', label='Baseline (MSE only)', linewidth=1)\n",
    "axes[1, 0].axhline(y=0.65, color='gray', linestyle=':', label='Target (≥0.65)', linewidth=1)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('CSI@74')\n",
    "axes[1, 0].set_title('Forecast Skill (CSI@74)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].axhline(y=baseline_lpips, color='black', linestyle='--', label='Baseline (MSE only)', linewidth=1)\n",
    "axes[1, 1].axhline(y=0.35, color='gray', linestyle=':', label='Target (<0.35)', linewidth=1)\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('LPIPS')\n",
    "axes[1, 1].set_title('Perceptual Quality (LPIPS, lower is better)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/stage4_lambda_sweep_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Plots saved to outputs/stage4_lambda_sweep_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Save Results to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy checkpoints and logs to Drive for safekeeping\n",
    "!mkdir -p /content/drive/MyDrive/stormfusion_results/stage4\n",
    "!cp -r outputs/checkpoints/*.pt /content/drive/MyDrive/stormfusion_results/stage4/\n",
    "!cp -r outputs/checkpoints/*.json /content/drive/MyDrive/stormfusion_results/stage4/\n",
    "!cp -r outputs/logs/*.log /content/drive/MyDrive/stormfusion_results/stage4/\n",
    "!cp outputs/stage4_lambda_sweep_curves.png /content/drive/MyDrive/stormfusion_results/stage4/\n",
    "\n",
    "print(\"✅ Results saved to Drive: /content/drive/MyDrive/stormfusion_results/stage4/\")\n",
    "print(\"\\nYou can now download:\")\n",
    "print(\"  - Best checkpoint: unet_perceptual_lambda{best_lambda}_best.pt\")\n",
    "print(\"  - Training curves: stage4_lambda_sweep_curves.png\")\n",
    "print(\"  - Full logs: outputs/logs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Generate Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "report = []\n",
    "report.append(\"=\"*80)\n",
    "report.append(\"STAGE 4: PERCEPTUAL LOSS LAMBDA SWEEP - FINAL REPORT\")\n",
    "report.append(\"=\"*80)\n",
    "report.append(\"\")\n",
    "report.append(f\"Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "report.append(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "report.append(f\"Total Training Time: {total_time/60:.1f} minutes\")\n",
    "report.append(\"\")\n",
    "report.append(\"Baseline (MSE only):\")\n",
    "report.append(f\"  CSI@74: 0.68\")\n",
    "report.append(f\"  LPIPS:  0.40\")\n",
    "report.append(\"\")\n",
    "report.append(\"-\"*80)\n",
    "report.append(\"\")\n",
    "\n",
    "for lambda_val in lambdas:\n",
    "    if 'error' in results_summary[lambda_val]:\n",
    "        report.append(f\"Lambda = {lambda_val}: FAILED\")\n",
    "        report.append(\"\")\n",
    "        continue\n",
    "    \n",
    "    res = results_summary[lambda_val]\n",
    "    csi = res['csi']\n",
    "    lpips = res['lpips']\n",
    "    mse = res['mse']\n",
    "    \n",
    "    csi_pass = \"PASS\" if csi >= 0.65 else \"FAIL\"\n",
    "    lpips_pass = \"PASS\" if lpips < 0.35 else \"FAIL\"\n",
    "    success = csi >= 0.65 and lpips < 0.35\n",
    "    \n",
    "    report.append(f\"Lambda = {lambda_val}:\")\n",
    "    report.append(f\"  Val CSI@74:  {csi:.3f} ({csi_pass})\")\n",
    "    report.append(f\"  Val LPIPS:   {lpips:.3f} ({lpips_pass})\")\n",
    "    report.append(f\"  Val MSE:     {mse:.4f}\")\n",
    "    report.append(f\"  Training Time: {res['time']/60:.1f} min\")\n",
    "    report.append(f\"  SUCCESS: {'YES' if success else 'NO'}\")\n",
    "    report.append(\"\")\n",
    "\n",
    "report.append(\"-\"*80)\n",
    "report.append(\"\")\n",
    "\n",
    "if best_lambda is not None:\n",
    "    report.append(f\"BEST LAMBDA: {best_lambda}\")\n",
    "    report.append(f\"  CSI@74: {results_summary[best_lambda]['csi']:.3f}\")\n",
    "    report.append(f\"  LPIPS:  {results_summary[best_lambda]['lpips']:.3f}\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"RECOMMENDATION: Use lambda={} for Stage 5\".format(best_lambda))\n",
    "else:\n",
    "    report.append(\"NO LAMBDA MET BOTH CRITERIA\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"RECOMMENDATION: Review results and either:\")\n",
    "    report.append(\"  1. Accept partial success (best CSI or best LPIPS)\")\n",
    "    report.append(\"  2. Try intermediate lambda values\")\n",
    "    report.append(\"  3. Adjust scaling factor\")\n",
    "\n",
    "report.append(\"\")\n",
    "report.append(\"=\"*80)\n",
    "report.append(\"See docs/WHY_PERCEPTUAL_LOSS_MATTERS.md for context\")\n",
    "report.append(\"=\"*80)\n",
    "\n",
    "report_text = \"\\n\".join(report)\n",
    "print(report_text)\n",
    "\n",
    "# Save report\n",
    "with open('outputs/logs/stage4_final_report.txt', 'w') as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "!cp outputs/logs/stage4_final_report.txt /content/drive/MyDrive/stormfusion_results/stage4/\n",
    "\n",
    "print(\"\\n✅ Report saved to outputs/logs/stage4_final_report.txt\")\n",
    "print(\"   and backed up to Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ✅ Stage 4 Complete!\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Review results above** - Which λ won?\n",
    "2. **Download checkpoint** from Drive if needed\n",
    "3. **Proceed to Stage 5** - Multi-step forecasting (6 frames)\n",
    "\n",
    "### Files Saved:\n",
    "- Checkpoints: `/content/drive/MyDrive/stormfusion_results/stage4/*.pt`\n",
    "- Histories: `/content/drive/MyDrive/stormfusion_results/stage4/*.json`\n",
    "- Plots: `stage4_lambda_sweep_curves.png`\n",
    "- Report: `stage4_final_report.txt`\n",
    "\n",
    "### Success Criteria:\n",
    "- ✅ CSI@74 ≥ 0.65 (maintains forecast skill)\n",
    "- ✅ LPIPS < 0.35 (improves sharpness)\n",
    "\n",
    "If both met: **Stage 4 SUCCESS!** 🎉\n",
    "\n",
    "### Remember:\n",
    "This enables spatial granularity in probabilistic forecasting (Stages 6-7).  \n",
    "See `docs/WHY_PERCEPTUAL_LOSS_MATTERS.md` for full context."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
