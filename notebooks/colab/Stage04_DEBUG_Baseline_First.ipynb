{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß Stage 4 DEBUG: Test Baseline First\n",
    "\n",
    "**CRITICAL FIX:** Previous run had CSI@74=0 for ALL lambdas.\n",
    "\n",
    "**This notebook:**\n",
    "1. Tests lambda=0 (pure MSE) FIRST\n",
    "2. Should match Stage 2 baseline (CSI@74 ~0.65-0.68)\n",
    "3. Adds detailed loss monitoring\n",
    "4. Only proceeds to perceptual if baseline works\n",
    "\n",
    "**Expected baseline results (lambda=0):**\n",
    "- Val MSE: ~0.009-0.012\n",
    "- Val CSI@74: ~0.65-0.68\n",
    "- Val LPIPS: ~0.40 (no improvement expected)\n",
    "\n",
    "**If baseline fails:** Data loading or model bug\n",
    "**If baseline works:** Can safely add perceptual loss\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Mount Drive & Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set data root\n",
    "DRIVE_DATA_ROOT = \"/content/drive/MyDrive/SEVIR_Data\"\n",
    "os.makedirs(DRIVE_DATA_ROOT, exist_ok=True)\n",
    "\n",
    "print(f\"‚úì Google Drive mounted\")\n",
    "print(f\"‚úì Data directory: {DRIVE_DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GPU CHECK\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: Select GPU runtime!\")\n",
    "    print(\"   Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q h5py lpips tqdm matplotlib scikit-image\n",
    "print(\"‚úì Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Data paths\n",
    "DATA_ROOT = \"/content/drive/MyDrive/SEVIR_Data\"\n",
    "SEVIR_ROOT = f\"{DATA_ROOT}/data/sevir\"\n",
    "CATALOG_PATH = f\"{DATA_ROOT}/data/SEVIR_CATALOG.csv\"\n",
    "\n",
    "# Check if data exists\n",
    "catalog_exists = Path(CATALOG_PATH).exists()\n",
    "vil_exists = Path(f\"{SEVIR_ROOT}/vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5\").exists()\n",
    "\n",
    "print(f\"Data Check:\")\n",
    "print(f\"  Catalog: {'‚úì' if catalog_exists else '‚úó'} {CATALOG_PATH}\")\n",
    "print(f\"  VIL data: {'‚úì' if vil_exists else '‚úó'} {SEVIR_ROOT}/vil/2019/\")\n",
    "\n",
    "if not (catalog_exists and vil_exists):\n",
    "    print(\"\\n‚ö† Data missing! Please ensure SEVIR data is in Drive.\")\n",
    "else:\n",
    "    print(\"\\n‚úì Data ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Event ID Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample directories\n",
    "os.makedirs(f\"{DATA_ROOT}/data/samples\", exist_ok=True)\n",
    "\n",
    "# Tiny train IDs (from Stage 1)\n",
    "train_ids = [\n",
    "    \"S851839\", \"S856840\", \"S853914\", \"S858016\",\n",
    "    \"S847132\", \"S828550\", \"S844358\", \"S833039\"\n",
    "]\n",
    "\n",
    "# Tiny val IDs (from Stage 1)\n",
    "val_ids = [\n",
    "    \"S848711\", \"S851205\", \"S849773\", \"S849364\"\n",
    "]\n",
    "\n",
    "TRAIN_IDS = f\"{DATA_ROOT}/data/samples/tiny_train_ids.txt\"\n",
    "VAL_IDS = f\"{DATA_ROOT}/data/samples/tiny_val_ids.txt\"\n",
    "\n",
    "with open(TRAIN_IDS, 'w') as f:\n",
    "    f.write('\\n'.join(train_ids))\n",
    "\n",
    "with open(VAL_IDS, 'w') as f:\n",
    "    f.write('\\n'.join(val_ids))\n",
    "\n",
    "print(f\"‚úì Created event ID files\")\n",
    "print(f\"  Train: {len(train_ids)} events\")\n",
    "print(f\"  Val: {len(val_ids)} events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SevirNowcastDataset(Dataset):\n",
    "    \"\"\"SEVIR VIL nowcasting dataset.\"\"\"\n",
    "    def __init__(self, index, input_steps=12, output_steps=1, target_size=(384, 384)):\n",
    "        self.index = index\n",
    "        self.in_steps = input_steps\n",
    "        self.out_steps = output_steps\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, file_index, event_id = self.index[idx]\n",
    "\n",
    "        # Load data from HDF5\n",
    "        with h5py.File(file_path, \"r\") as h5:\n",
    "            data = h5[\"vil\"][file_index].astype(np.float32) / 255.0\n",
    "\n",
    "        # Random temporal crop\n",
    "        total_frames = data.shape[2]\n",
    "        max_start = total_frames - (self.in_steps + self.out_steps)\n",
    "        t_start = np.random.randint(0, max(1, max_start + 1))\n",
    "\n",
    "        # Extract sequences: (H, W, T) ‚Üí (T, H, W)\n",
    "        x = data[:, :, t_start:t_start + self.in_steps]\n",
    "        y = data[:, :, t_start + self.in_steps:t_start + self.in_steps + self.out_steps]\n",
    "\n",
    "        x = np.transpose(x, (2, 0, 1))\n",
    "        y = np.transpose(y, (2, 0, 1))\n",
    "\n",
    "        return torch.from_numpy(x).float(), torch.from_numpy(y).float()\n",
    "\n",
    "\n",
    "def build_tiny_index(catalog_path, ids_txt, sevir_root, modality=\"vil\"):\n",
    "    \"\"\"Build index for tiny dataset.\"\"\"\n",
    "    with open(ids_txt, 'r') as f:\n",
    "        event_ids = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    catalog = pd.read_csv(catalog_path, low_memory=False)\n",
    "    modality_cat = catalog[catalog[\"img_type\"] == modality].copy()\n",
    "\n",
    "    index = []\n",
    "    for event_id in event_ids:\n",
    "        event_rows = modality_cat[modality_cat[\"id\"] == event_id]\n",
    "        if event_rows.empty:\n",
    "            continue\n",
    "\n",
    "        row = event_rows.iloc[0]\n",
    "        file_path = os.path.join(sevir_root, row[\"file_name\"])\n",
    "        if os.path.exists(file_path):\n",
    "            index.append((file_path, int(row[\"file_index\"]), event_id))\n",
    "\n",
    "    print(f\"‚úì Built index: {len(index)} events\")\n",
    "    return index\n",
    "\n",
    "print(\"‚úì Dataset classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architecture (U-Net2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv_block(in_ch, out_ch, use_bn=True):\n",
    "    layers = [nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.ReLU(inplace=True)]\n",
    "    if use_bn: layers.append(nn.BatchNorm2d(out_ch))\n",
    "    layers += [nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.ReLU(inplace=True)]\n",
    "    if use_bn: layers.append(nn.BatchNorm2d(out_ch))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, use_bn=True):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.block = conv_block(in_ch, out_ch, use_bn)\n",
    "    def forward(self, x): return self.block(self.pool(x))\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, use_bn=True):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "        self.block = conv_block(in_ch, out_ch, use_bn)\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        dy, dx = skip.size(-2) - x.size(-2), skip.size(-1) - x.size(-1)\n",
    "        if dy or dx:\n",
    "            x = F.pad(x, [dx//2, dx - dx//2, dy//2, dy - dy//2])\n",
    "        x = torch.cat([skip, x], dim=1)\n",
    "        return self.block(x)\n",
    "\n",
    "class UNet2D(nn.Module):\n",
    "    def __init__(self, in_channels=12, out_channels=1, base_ch=32, use_bn=True):\n",
    "        super().__init__()\n",
    "        self.inc = conv_block(in_channels, base_ch, use_bn)\n",
    "        self.d1 = Down(base_ch, base_ch*2, use_bn)\n",
    "        self.d2 = Down(base_ch*2, base_ch*4, use_bn)\n",
    "        self.d3 = Down(base_ch*4, base_ch*8, use_bn)\n",
    "        self.bottleneck = conv_block(base_ch*8, base_ch*16, use_bn)\n",
    "        self.u3 = Up(base_ch*16, base_ch*8, use_bn)\n",
    "        self.u2 = Up(base_ch*8, base_ch*4, use_bn)\n",
    "        self.u1 = Up(base_ch*4, base_ch*2, use_bn)\n",
    "        self.u0 = Up(base_ch*2, base_ch, use_bn)\n",
    "        self.outc = nn.Conv2d(base_ch, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.inc(x)\n",
    "        c2 = self.d1(c1)\n",
    "        c3 = self.d2(c2)\n",
    "        c4 = self.d3(c3)\n",
    "        b  = self.bottleneck(c4)\n",
    "        x = self.u3(b, c4)\n",
    "        x = self.u2(x, c3)\n",
    "        x = self.u1(x, c2)\n",
    "        x = self.u0(x, c1)\n",
    "        return self.outc(x)\n",
    "\n",
    "print(\"‚úì U-Net2D model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Forecast Metrics & LPIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIP_THRESHOLDS = [16, 74, 133, 160, 181, 219]\n",
    "\n",
    "def binarize(x, thr):\n",
    "    return (x >= thr/255.0).to(torch.int32)\n",
    "\n",
    "def scores(pred, truth, thresholds=VIP_THRESHOLDS):\n",
    "    \"\"\"Return dict of POD, SUCR, CSI, BIAS for each threshold.\"\"\"\n",
    "    out = {}\n",
    "    for t in thresholds:\n",
    "        p = binarize(pred, t)\n",
    "        y = binarize(truth, t)\n",
    "        hits = ((p==1)&(y==1)).sum().item()\n",
    "        miss = ((p==0)&(y==1)).sum().item()\n",
    "        fa   = ((p==1)&(y==0)).sum().item()\n",
    "        pod = hits / (hits + miss + 1e-9)\n",
    "        sucr = hits / (hits + fa + 1e-9)\n",
    "        csi = hits / (hits + miss + fa + 1e-9)\n",
    "        bias = (hits + fa) / (hits + miss + 1e-9)\n",
    "        out[t] = dict(POD=pod, SUCR=sucr, CSI=csi, BIAS=bias)\n",
    "    return out\n",
    "\n",
    "# LPIPS\n",
    "import lpips\n",
    "lpips_fn = lpips.LPIPS(net='alex').cuda() if torch.cuda.is_available() else lpips.LPIPS(net='alex')\n",
    "\n",
    "def compute_lpips(pred, target):\n",
    "    if pred.shape[1] == 1:\n",
    "        pred = pred.repeat(1, 3, 1, 1)\n",
    "        target = target.repeat(1, 3, 1, 1)\n",
    "    return lpips_fn(pred, target).mean().item()\n",
    "\n",
    "print(\"‚úì Metrics defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Function (WITH DETAILED LOGGING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import time\n",
    "\n",
    "def train_baseline(epochs=10, batch_size=4, lr=1e-4):\n",
    "    \"\"\"Train PURE MSE baseline (lambda=0) to verify pipeline works.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"BASELINE TEST (LAMBDA = 0.0)\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load datasets\n",
    "    train_index = build_tiny_index(CATALOG_PATH, TRAIN_IDS, SEVIR_ROOT, \"vil\")\n",
    "    val_index = build_tiny_index(CATALOG_PATH, VAL_IDS, SEVIR_ROOT, \"vil\")\n",
    "    \n",
    "    train_dataset = SevirNowcastDataset(train_index, 12, 1)\n",
    "    val_dataset = SevirNowcastDataset(val_index, 12, 1)\n",
    "    \n",
    "    from torch.utils.data import DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    # Create model\n",
    "    model = UNet2D(12, 1, 32, True).to(device)\n",
    "    mse_criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None\n",
    "    \n",
    "    history = {'train_loss': [], 'val_mse': [], 'val_lpips': [], 'val_csi_74': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if scaler is not None:\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    pred = model(x)\n",
    "                    loss = mse_criterion(pred, y)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                pred = model(x)\n",
    "                loss = mse_criterion(pred, y)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_mse = 0\n",
    "        val_lpips_total = 0\n",
    "        all_csi = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                pred = model(x)\n",
    "                val_mse += mse_criterion(pred, y).item()\n",
    "                val_lpips_total += compute_lpips(pred, y)\n",
    "                \n",
    "                batch_scores = scores(pred, y)\n",
    "                all_csi.append(batch_scores[74]['CSI'])\n",
    "        \n",
    "        val_mse /= len(val_loader)\n",
    "        val_lpips_avg = val_lpips_total / len(val_loader)\n",
    "        csi_74 = np.mean(all_csi)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_mse'].append(val_mse)\n",
    "        history['val_lpips'].append(val_lpips_avg)\n",
    "        history['val_csi_74'].append(csi_74)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train={train_loss:.4f}, Val MSE={val_mse:.4f}, LPIPS={val_lpips_avg:.4f}, CSI@74={csi_74:.3f}\")\n",
    "    \n",
    "    # Save\n",
    "    os.makedirs('/content/outputs/checkpoints', exist_ok=True)\n",
    "    torch.save({'model': model.state_dict(), 'history': history}, '/content/outputs/checkpoints/baseline_lambda0.pt')\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"‚úì Baseline training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. RUN BASELINE TEST FIRST! üîß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_history = train_baseline(epochs=10, batch_size=4)\n",
    "\n",
    "final_csi = baseline_history['val_csi_74'][-1]\n",
    "final_mse = baseline_history['val_mse'][-1]\n",
    "final_lpips = baseline_history['val_lpips'][-1]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"BASELINE RESULTS (Lambda=0)\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Final Val MSE:    {final_mse:.4f} (expected: ~0.009-0.012)\")\n",
    "print(f\"Final Val CSI@74: {final_csi:.3f} (expected: ~0.65-0.68)\")\n",
    "print(f\"Final Val LPIPS:  {final_lpips:.3f} (expected: ~0.40)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "if final_csi >= 0.60:\n",
    "    print(\"‚úÖ BASELINE WORKS! Pipeline is correct.\")\n",
    "    print(\"   ‚Üí Safe to proceed with perceptual loss sweep\")\n",
    "else:\n",
    "    print(\"‚ùå BASELINE FAILED! CSI too low.\")\n",
    "    print(\"   ‚Üí Bug in data loading, model, or training loop\")\n",
    "    print(\"   ‚Üí DO NOT proceed to perceptual loss yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Baseline Results to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /content/drive/MyDrive/stormfusion_results/stage4_debug\n",
    "!cp -r /content/outputs/checkpoints/* /content/drive/MyDrive/stormfusion_results/stage4_debug/\n",
    "\n",
    "# Save summary\n",
    "summary = f\"\"\"Stage 4 DEBUG: Baseline Test\n",
    "============================\n",
    "Lambda: 0.0 (pure MSE)\n",
    "Final Val MSE: {final_mse:.4f}\n",
    "Final Val CSI@74: {final_csi:.3f}\n",
    "Final Val LPIPS: {final_lpips:.3f}\n",
    "\n",
    "Expected: CSI ~0.65-0.68\n",
    "Status: {'PASS ‚úÖ' if final_csi >= 0.60 else 'FAIL ‚ùå'}\n",
    "\"\"\"\n",
    "\n",
    "with open('/content/drive/MyDrive/stormfusion_results/stage4_debug/baseline_summary.txt', 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"‚úÖ Baseline results saved to Drive!\")\n",
    "print(f\"   Location: /content/drive/MyDrive/stormfusion_results/stage4_debug/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ NEXT STEPS\n",
    "\n",
    "**If baseline PASSED (CSI ‚â• 0.60):**\n",
    "- Pipeline is working correctly\n",
    "- Can now safely add perceptual loss\n",
    "- The previous failure was due to perceptual loss being too strong\n",
    "- Try MUCH LOWER lambda values: {0.00001, 0.00005, 0.0001}\n",
    "\n",
    "**If baseline FAILED (CSI < 0.60):**\n",
    "- Bug in data loading, model, or training\n",
    "- Compare to Stage 2 baseline script\n",
    "- Check data shapes, loss values, gradient flow\n",
    "- DO NOT add perceptual loss until baseline works"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
