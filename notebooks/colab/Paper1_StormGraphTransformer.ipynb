{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Paper 1: Storm-Graph Transformer (SGT)\n",
    "\n",
    "**Title:** \"Physics-Informed Graph Neural Networks with Transformers for Severe Weather Nowcasting\"\n",
    "\n",
    "**Core Innovation:**\n",
    "- Hybrid GNN-Transformer-Physics architecture\n",
    "- Treats storms as discrete graph nodes (not continuous fields)\n",
    "- Physics-constrained predictions (conservation laws)\n",
    "- Interpretable attention (which storms matter?)\n",
    "\n",
    "**Timeline:** Week 1-3 (Oct 10-31)\n",
    "**Target:** ArXiv + NeurIPS workshop\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Sections:\n",
    "1. Setup & Data Verification\n",
    "2. Multimodal Data Loading\n",
    "3. Architecture Implementation\n",
    "4. Training Pipeline\n",
    "5. Evaluation & Analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive/SEVIR_Data\"\n",
    "print(f\"‚úì Drive mounted: {DRIVE_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch-geometric torch-scatter torch-sparse\n",
    "!pip install -q h5py pandas tqdm matplotlib lpips scikit-image\n",
    "\n",
    "print(\"‚úì Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone/pull latest repo\n",
    "import os\n",
    "if not os.path.exists('/content/stormfusion-sevir'):\n",
    "    !git clone https://github.com/syedhaliz/stormfusion-sevir.git\n",
    "else:\n",
    "    !cd stormfusion-sevir && git pull\n",
    "\n",
    "# Add to path\n",
    "import sys\n",
    "sys.path.insert(0, '/content/stormfusion-sevir')\n",
    "\n",
    "print(\"‚úì Repo ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify SEVIR Modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run verification script\n",
    "from pathlib import Path\n",
    "\n",
    "SEVIR_ROOT = f\"{DRIVE_ROOT}/data/sevir\"\n",
    "CATALOG_PATH = f\"{DRIVE_ROOT}/data/SEVIR_CATALOG.csv\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SEVIR DATA VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "modalities = {\n",
    "    'vil': 'VIL (Radar)',\n",
    "    'ir069': 'GOES-16 C09 (Water Vapor 6.9Œºm)',\n",
    "    'ir107': 'GOES-16 C13 (IR Window 10.7Œºm)',\n",
    "    'lght': 'GOES-16 GLM (Lightning)'\n",
    "}\n",
    "\n",
    "available = []\n",
    "missing = []\n",
    "\n",
    "for mod, desc in modalities.items():\n",
    "    mod_path = Path(SEVIR_ROOT) / mod / \"2019\"\n",
    "    if mod_path.exists():\n",
    "        h5_files = list(mod_path.glob(\"*.h5\"))\n",
    "        available.append(mod)\n",
    "        print(f\"‚úÖ {mod:8s} - {desc}\")\n",
    "        print(f\"   Files: {len(h5_files)} HDF5 files\\n\")\n",
    "    else:\n",
    "        missing.append(mod)\n",
    "        print(f\"‚ùå {mod:8s} - {desc}\")\n",
    "        print(f\"   Missing: {mod_path}\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"Available: {len(available)}/4 modalities\")\n",
    "if available:\n",
    "    print(f\"  {', '.join(available)}\")\n",
    "if missing:\n",
    "    print(f\"\\n‚ö†Ô∏è  Missing: {', '.join(missing)}\")\n",
    "    print(f\"   Download from: https://sevir.mit.edu/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multimodal Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import multimodal dataset\n",
    "from stormfusion.data.sevir_multimodal import (\n",
    "    SEVIRMultiModalDataset,\n",
    "    build_multimodal_index,\n",
    "    multimodal_collate_fn\n",
    ")\n",
    "\n",
    "print(\"‚úì Multimodal dataset imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build index (use ALL 541 events)\n",
    "TRAIN_IDS = f\"{DRIVE_ROOT}/data/samples/all_train_ids.txt\"\n",
    "VAL_IDS = f\"{DRIVE_ROOT}/data/samples/all_val_ids.txt\"\n",
    "\n",
    "train_index = build_multimodal_index(CATALOG_PATH, TRAIN_IDS, SEVIR_ROOT)\n",
    "val_index = build_multimodal_index(CATALOG_PATH, VAL_IDS, SEVIR_ROOT)\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"  Train: {len(train_index)} events\")\n",
    "print(f\"  Val: {len(val_index)} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = SEVIRMultiModalDataset(\n",
    "    train_index,\n",
    "    sevir_root=SEVIR_ROOT,\n",
    "    catalog_path=CATALOG_PATH,\n",
    "    input_steps=12,\n",
    "    output_steps=6,\n",
    "    normalize=True,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "val_dataset = SEVIRMultiModalDataset(\n",
    "    val_index,\n",
    "    sevir_root=SEVIR_ROOT,\n",
    "    catalog_path=CATALOG_PATH,\n",
    "    input_steps=12,\n",
    "    output_steps=6,\n",
    "    normalize=True,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "print(\"‚úì Datasets created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data loading\n",
    "print(\"Testing data loading...\\n\")\n",
    "\n",
    "inputs, outputs = train_dataset[0]\n",
    "\n",
    "print(\"Input shapes:\")\n",
    "for modality, data in inputs.items():\n",
    "    print(f\"  {modality:8s}: {tuple(data.shape)} (T, H, W)\")\n",
    "\n",
    "print(\"\\nOutput shapes:\")\n",
    "for modality, data in outputs.items():\n",
    "    print(f\"  {modality:8s}: {tuple(data.shape)} (T, H, W)\")\n",
    "\n",
    "print(\"\\n‚úÖ Multimodal loading successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Show last input frame for each modality\n",
    "for i, modality in enumerate(['vil', 'ir069', 'ir107', 'lght']):\n",
    "    data = inputs[modality][-1].numpy()  # Last timestep\n",
    "    axes[0, i].imshow(data, cmap='viridis', vmin=data.min(), vmax=data.max())\n",
    "    axes[0, i].set_title(f'{modality.upper()} (input t=12)')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Show VIL predictions\n",
    "for i in range(4):\n",
    "    data = outputs['vil'][i].numpy()\n",
    "    axes[1, i].imshow(data, cmap='viridis', vmin=0, vmax=1)\n",
    "    axes[1, i].set_title(f'VIL (pred t+{(i+1)*5}min)')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/multimodal_sample.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualization saved to /content/multimodal_sample.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Architecture Implementation\n\n**Status:** ‚úÖ **ALL MODULES IMPLEMENTED!**\n\n### Module Status:\n1. ‚úÖ Multimodal Encoder (CNN per modality)\n2. ‚úÖ Storm Cell Detector (graph construction)\n3. ‚úÖ GNN Module (storm interactions)\n4. ‚úÖ Transformer Module (spatiotemporal attention)\n5. ‚úÖ Physics Decoder (conservation laws)\n6. ‚úÖ End-to-End Integration\n\n**Ready for training!**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import SGT architecture\nfrom stormfusion.models.sgt import create_sgt_model\n\n# Create model\nprint(\"Creating Storm-Graph Transformer...\")\n\nmodel_config = {\n    'modalities': ['vil', 'ir069', 'ir107', 'lght'],\n    'input_steps': 12,\n    'output_steps': 6,\n    'hidden_dim': 128,\n    'gnn_layers': 3,\n    'transformer_layers': 4,\n    'num_heads': 8,\n    'use_physics': True\n}\n\nmodel = create_sgt_model(model_config)\n\n# Count parameters\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"‚úÖ SGT Model Created!\")\nprint(f\"   Total parameters: {total_params:,}\")\nprint(f\"   Trainable parameters: {trainable_params:,}\")\nprint(f\"   Model size: ~{total_params * 4 / 1e6:.1f} MB (float32)\")\n\n# Move to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\nprint(f\"   Device: {device}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Test Forward Pass\n\nQuick test to verify everything works before training"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test forward pass with one sample\nprint(\"Testing forward pass...\")\n\n# Get one sample\ninputs, targets = train_dataset[0]\n\n# Add batch dimension and move to device\ninputs_batch = {\n    mod: data.unsqueeze(0).to(device) for mod, data in inputs.items()\n}\ntargets_batch = targets['vil'].unsqueeze(0).to(device)\n\nprint(f\"\\nInput batch shapes:\")\nfor mod, data in inputs_batch.items():\n    print(f\"  {mod:8s}: {tuple(data.shape)}\")\n\n# Forward pass\nwith torch.no_grad():\n    predictions, attention_info, physics_info = model(inputs_batch)\n\nprint(f\"\\n‚úÖ Forward pass successful!\")\nprint(f\"   Predictions: {tuple(predictions.shape)}\")\nprint(f\"   Min/Max: [{predictions.min():.3f}, {predictions.max():.3f}]\")\n\n# Test loss computation\nloss, loss_dict = model.compute_loss(predictions, targets_batch, physics_info)\n\nprint(f\"\\n‚úÖ Loss computation successful!\")\nprint(f\"   Total loss: {loss.item():.4f}\")\nprint(f\"   Components:\")\nfor name, value in loss_dict.items():\n    if name != 'total':\n        print(f\"      {name:12s}: {value:.4f}\")\n\nprint(\"\\nüéâ Model ready for training!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Training Pipeline\n\nFull training loop with checkpointing and logging"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Training configuration\nfrom torch.utils.data import DataLoader\nfrom stormfusion.data.sevir_multimodal import multimodal_collate_fn\nfrom tqdm import tqdm\nimport time\n\n# Config\nBATCH_SIZE = 4\nLR = 1e-4\nEPOCHS = 20\nLAMBDA_MSE = 1.0\nLAMBDA_PHYSICS = 0.1\nLAMBDA_EXTREME = 2.0\n\nCHECKPOINT_DIR = \"/content/drive/MyDrive/SEVIR_Data/checkpoints/paper1_sgt\"\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\nprint(f\"Training Configuration:\")\nprint(f\"  Batch size: {BATCH_SIZE}\")\nprint(f\"  Learning rate: {LR}\")\nprint(f\"  Epochs: {EPOCHS}\")\nprint(f\"  Loss weights: MSE={LAMBDA_MSE}, Physics={LAMBDA_PHYSICS}, Extreme={LAMBDA_EXTREME}\")\nprint(f\"  Checkpoint dir: {CHECKPOINT_DIR}\")\n\n# DataLoaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=2,\n    collate_fn=multimodal_collate_fn,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=2,\n    collate_fn=multimodal_collate_fn,\n    pin_memory=True\n)\n\nprint(f\"\\n‚úÖ DataLoaders created:\")\nprint(f\"   Train batches: {len(train_loader)}\")\nprint(f\"   Val batches: {len(val_loader)}\")\n\n# Optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n\n# Scheduler\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n)\n\nprint(f\"\\n‚úÖ Optimizer: AdamW (lr={LR})\")\nprint(f\"‚úÖ Scheduler: ReduceLROnPlateau\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö References\n",
    "\n",
    "**Architecture Design:**\n",
    "- See: `docs/PAPER1_ARCHITECTURE.md` in repo\n",
    "\n",
    "**Multimodal Data:**\n",
    "- SEVIR: Veillette et al., NeurIPS 2020\n",
    "- 4 modalities: VIL, IR069, IR107, GLM\n",
    "- 541 events (432 train / 109 val)\n",
    "\n",
    "**Novel Contributions:**\n",
    "1. GNN-Transformer hybrid for weather nowcasting\n",
    "2. Physics-informed graph construction\n",
    "3. Interpretable attention mechanisms\n",
    "4. Extreme event focus (Stage 4 insights)\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook will be updated as modules are implemented.*\n",
    "*Check git repo for latest code: https://github.com/syedhaliz/stormfusion-sevir*"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Main training loop\nprint(\"=\"*70)\nprint(\"STARTING TRAINING\")\nprint(\"=\"*70)\n\nbest_val_loss = float('inf')\nhistory = {'train_loss': [], 'val_loss': []}\n\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n    print(\"-\" * 70)\n    \n    start_time = time.time()\n    \n    # Train\n    train_loss, train_components = train_epoch(model, train_loader, optimizer, device)\n    \n    # Validate\n    val_loss, val_components = validate(model, val_loader, device)\n    \n    # Scheduler step\n    scheduler.step(val_loss)\n    \n    epoch_time = time.time() - start_time\n    \n    # Log\n    print(f\"\\nEpoch {epoch+1} Summary:\")\n    print(f\"  Train Loss: {train_loss:.4f} (MSE: {train_components['mse']:.4f}, \"\n          f\"Extreme: {train_components['extreme']:.4f}, Physics: {train_components['physics']:.4f})\")\n    print(f\"  Val Loss:   {val_loss:.4f} (MSE: {val_components['mse']:.4f}, \"\n          f\"Extreme: {val_components['extreme']:.4f}, Physics: {val_components['physics']:.4f})\")\n    print(f\"  Time: {epoch_time:.1f}s\")\n    \n    # Save history\n    history['train_loss'].append(train_loss)\n    history['val_loss'].append(val_loss)\n    \n    # Save checkpoint\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        checkpoint = {\n            'epoch': epoch + 1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'val_loss': val_loss,\n            'config': model_config\n        }\n        checkpoint_path = f\"{CHECKPOINT_DIR}/best_model.pt\"\n        torch.save(checkpoint, checkpoint_path)\n        print(f\"  ‚úÖ Saved best model (val_loss: {val_loss:.4f})\")\n    \n    # Save latest\n    checkpoint = {\n        'epoch': epoch + 1,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict(),\n        'val_loss': val_loss,\n        'config': model_config,\n        'history': history\n    }\n    torch.save(checkpoint, f\"{CHECKPOINT_DIR}/latest_model.pt\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"TRAINING COMPLETE!\")\nprint(\"=\"*70)\nprint(f\"Best validation loss: {best_val_loss:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Training loop\ndef train_epoch(model, loader, optimizer, device):\n    model.train()\n    total_loss = 0\n    loss_components = {'mse': 0, 'extreme': 0, 'physics': 0}\n    \n    pbar = tqdm(loader, desc=\"Training\")\n    for batch_idx, (inputs, targets) in enumerate(pbar):\n        # Move to device\n        inputs = {mod: data.to(device) for mod, data in inputs.items()}\n        targets = targets['vil'].to(device)\n        \n        # Forward\n        optimizer.zero_grad()\n        predictions, attention_info, physics_info = model(inputs)\n        \n        # Loss\n        loss, loss_dict = model.compute_loss(\n            predictions, targets, physics_info,\n            lambda_mse=LAMBDA_MSE,\n            lambda_physics=LAMBDA_PHYSICS,\n            lambda_extreme=LAMBDA_EXTREME\n        )\n        \n        # Backward\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        \n        # Accumulate\n        total_loss += loss.item()\n        for key in loss_components:\n            if key in loss_dict:\n                loss_components[key] += loss_dict[key]\n        \n        # Update progress bar\n        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n    \n    # Average\n    n = len(loader)\n    total_loss /= n\n    for key in loss_components:\n        loss_components[key] /= n\n    \n    return total_loss, loss_components\n\n\ndef validate(model, loader, device):\n    model.eval()\n    total_loss = 0\n    loss_components = {'mse': 0, 'extreme': 0, 'physics': 0}\n    \n    with torch.no_grad():\n        pbar = tqdm(loader, desc=\"Validation\")\n        for inputs, targets in pbar:\n            inputs = {mod: data.to(device) for mod, data in inputs.items()}\n            targets = targets['vil'].to(device)\n            \n            predictions, attention_info, physics_info = model(inputs)\n            \n            loss, loss_dict = model.compute_loss(\n                predictions, targets, physics_info,\n                lambda_mse=LAMBDA_MSE,\n                lambda_physics=LAMBDA_PHYSICS,\n                lambda_extreme=LAMBDA_EXTREME\n            )\n            \n            total_loss += loss.item()\n            for key in loss_components:\n                if key in loss_dict:\n                    loss_components[key] += loss_dict[key]\n    \n    # Average\n    n = len(loader)\n    total_loss /= n\n    for key in loss_components:\n        loss_components[key] /= n\n    \n    return total_loss, loss_components\n\n\nprint(\"‚úÖ Training functions defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}