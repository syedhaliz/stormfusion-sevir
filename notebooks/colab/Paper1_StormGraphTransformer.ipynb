{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Paper 1: Storm-Graph Transformer (SGT)\n",
    "\n",
    "**Title:** \"Physics-Informed Graph Neural Networks with Transformers for Severe Weather Nowcasting\"\n",
    "\n",
    "**Core Innovation:**\n",
    "- Hybrid GNN-Transformer-Physics architecture\n",
    "- Treats storms as discrete graph nodes (not continuous fields)\n",
    "- Physics-constrained predictions (conservation laws)\n",
    "- Interpretable attention (which storms matter?)\n",
    "\n",
    "**Timeline:** Week 1-3 (Oct 10-31)\n",
    "**Target:** ArXiv + NeurIPS workshop\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Sections:\n",
    "1. Setup & Data Verification\n",
    "2. Multimodal Data Loading\n",
    "3. Architecture Implementation\n",
    "4. Training Pipeline\n",
    "5. Evaluation & Analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive/SEVIR_Data\"\n",
    "print(f\"‚úì Drive mounted: {DRIVE_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch-geometric torch-scatter torch-sparse\n",
    "!pip install -q h5py pandas tqdm matplotlib lpips scikit-image\n",
    "\n",
    "print(\"‚úì Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone/pull latest repo\n",
    "import os\n",
    "if not os.path.exists('/content/stormfusion-sevir'):\n",
    "    !git clone https://github.com/syedhaliz/stormfusion-sevir.git\n",
    "else:\n",
    "    !cd stormfusion-sevir && git pull\n",
    "\n",
    "# Add to path\n",
    "import sys\n",
    "sys.path.insert(0, '/content/stormfusion-sevir')\n",
    "\n",
    "print(\"‚úì Repo ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify SEVIR Modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run verification script\n",
    "from pathlib import Path\n",
    "\n",
    "SEVIR_ROOT = f\"{DRIVE_ROOT}/data/sevir\"\n",
    "CATALOG_PATH = f\"{DRIVE_ROOT}/data/SEVIR_CATALOG.csv\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SEVIR DATA VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "modalities = {\n",
    "    'vil': 'VIL (Radar)',\n",
    "    'ir069': 'GOES-16 C09 (Water Vapor 6.9Œºm)',\n",
    "    'ir107': 'GOES-16 C13 (IR Window 10.7Œºm)',\n",
    "    'lght': 'GOES-16 GLM (Lightning)'\n",
    "}\n",
    "\n",
    "available = []\n",
    "missing = []\n",
    "\n",
    "for mod, desc in modalities.items():\n",
    "    mod_path = Path(SEVIR_ROOT) / mod / \"2019\"\n",
    "    if mod_path.exists():\n",
    "        h5_files = list(mod_path.glob(\"*.h5\"))\n",
    "        available.append(mod)\n",
    "        print(f\"‚úÖ {mod:8s} - {desc}\")\n",
    "        print(f\"   Files: {len(h5_files)} HDF5 files\\n\")\n",
    "    else:\n",
    "        missing.append(mod)\n",
    "        print(f\"‚ùå {mod:8s} - {desc}\")\n",
    "        print(f\"   Missing: {mod_path}\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"Available: {len(available)}/4 modalities\")\n",
    "if available:\n",
    "    print(f\"  {', '.join(available)}\")\n",
    "if missing:\n",
    "    print(f\"\\n‚ö†Ô∏è  Missing: {', '.join(missing)}\")\n",
    "    print(f\"   Download from: https://sevir.mit.edu/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multimodal Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import multimodal dataset\n",
    "from stormfusion.data.sevir_multimodal import (\n",
    "    SEVIRMultiModalDataset,\n",
    "    build_multimodal_index,\n",
    "    multimodal_collate_fn\n",
    ")\n",
    "\n",
    "print(\"‚úì Multimodal dataset imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build index (use ALL 541 events)\n",
    "TRAIN_IDS = f\"{DRIVE_ROOT}/data/samples/all_train_ids.txt\"\n",
    "VAL_IDS = f\"{DRIVE_ROOT}/data/samples/all_val_ids.txt\"\n",
    "\n",
    "train_index = build_multimodal_index(CATALOG_PATH, TRAIN_IDS, SEVIR_ROOT)\n",
    "val_index = build_multimodal_index(CATALOG_PATH, VAL_IDS, SEVIR_ROOT)\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"  Train: {len(train_index)} events\")\n",
    "print(f\"  Val: {len(val_index)} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = SEVIRMultiModalDataset(\n",
    "    train_index,\n",
    "    sevir_root=SEVIR_ROOT,\n",
    "    catalog_path=CATALOG_PATH,\n",
    "    input_steps=12,\n",
    "    output_steps=6,\n",
    "    normalize=True,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "val_dataset = SEVIRMultiModalDataset(\n",
    "    val_index,\n",
    "    sevir_root=SEVIR_ROOT,\n",
    "    catalog_path=CATALOG_PATH,\n",
    "    input_steps=12,\n",
    "    output_steps=6,\n",
    "    normalize=True,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "print(\"‚úì Datasets created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data loading\n",
    "print(\"Testing data loading...\\n\")\n",
    "\n",
    "inputs, outputs = train_dataset[0]\n",
    "\n",
    "print(\"Input shapes:\")\n",
    "for modality, data in inputs.items():\n",
    "    print(f\"  {modality:8s}: {tuple(data.shape)} (T, H, W)\")\n",
    "\n",
    "print(\"\\nOutput shapes:\")\n",
    "for modality, data in outputs.items():\n",
    "    print(f\"  {modality:8s}: {tuple(data.shape)} (T, H, W)\")\n",
    "\n",
    "print(\"\\n‚úÖ Multimodal loading successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Show last input frame for each modality\n",
    "for i, modality in enumerate(['vil', 'ir069', 'ir107', 'lght']):\n",
    "    data = inputs[modality][-1].numpy()  # Last timestep\n",
    "    axes[0, i].imshow(data, cmap='viridis', vmin=data.min(), vmax=data.max())\n",
    "    axes[0, i].set_title(f'{modality.upper()} (input t=12)')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Show VIL predictions\n",
    "for i in range(4):\n",
    "    data = outputs['vil'][i].numpy()\n",
    "    axes[1, i].imshow(data, cmap='viridis', vmin=0, vmax=1)\n",
    "    axes[1, i].set_title(f'VIL (pred t+{(i+1)*5}min)')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/multimodal_sample.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualization saved to /content/multimodal_sample.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Architecture Implementation\n",
    "\n",
    "**Status:** Building modules progressively\n",
    "\n",
    "### Module Plan:\n",
    "1. ‚úÖ Multimodal Encoder (CNN per modality)\n",
    "2. ‚è≥ Storm Cell Detector (graph construction)\n",
    "3. ‚è≥ GNN Module (storm interactions)\n",
    "4. ‚è≥ Transformer Module (spatiotemporal attention)\n",
    "5. ‚è≥ Physics Decoder (conservation laws)\n",
    "\n",
    "**Note:** Modules will be added as they're implemented in the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder: Will import architecture modules as they're built\n",
    "\n",
    "# from stormfusion.models.sgt import StormGraphTransformer\n",
    "# from stormfusion.models.sgt.encoder import MultiModalEncoder\n",
    "# from stormfusion.models.sgt.detector import StormCellDetector\n",
    "# from stormfusion.models.sgt.gnn import StormGNN\n",
    "# from stormfusion.models.sgt.transformer import SpatioTemporalTransformer\n",
    "# from stormfusion.models.sgt.decoder import PhysicsDecoder\n",
    "\n",
    "print(\"‚è≥ Architecture modules coming soon...\")\n",
    "print(\"   Check repo for latest updates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Pipeline (Placeholder)\n",
    "\n",
    "Will be activated once architecture is implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "CONFIG = {\n",
    "    'model': {\n",
    "        'hidden_dim': 128,\n",
    "        'num_gnn_layers': 3,\n",
    "        'num_tf_layers': 4,\n",
    "        'num_heads': 8\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 4,\n",
    "        'lr': 1e-4,\n",
    "        'epochs': 20,\n",
    "        'lambda_physics': 0.1,\n",
    "        'lambda_extreme': 2.0  # Stage 4 insight: weight extreme events\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Training config:\")\n",
    "import json\n",
    "print(json.dumps(CONFIG, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Status & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PAPER 1 STATUS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "status = {\n",
    "    'Architecture Design': '‚úÖ Complete',\n",
    "    'Multimodal Data Loader': '‚úÖ Complete',\n",
    "    'Storm Cell Detection': '‚è≥ In Progress',\n",
    "    'GNN Module': '‚è≥ Pending',\n",
    "    'Transformer Module': '‚è≥ Pending',\n",
    "    'Physics Decoder': '‚è≥ Pending',\n",
    "    'Training Pipeline': '‚è≥ Pending',\n",
    "    'Evaluation': '‚è≥ Pending'\n",
    "}\n",
    "\n",
    "for item, state in status.items():\n",
    "    print(f\"{item:30s} {state}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TIMELINE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nWeek 1 (Oct 10-17): Core modules\")\n",
    "print(\"Week 2 (Oct 17-24): Full training\")\n",
    "print(\"Week 3 (Oct 24-31): Experiments + baselines\")\n",
    "print(\"Week 4 (Oct 31-Nov 7): Paper writing\")\n",
    "\n",
    "print(\"\\n‚úÖ Data loading verified - ready to build architecture!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö References\n",
    "\n",
    "**Architecture Design:**\n",
    "- See: `docs/PAPER1_ARCHITECTURE.md` in repo\n",
    "\n",
    "**Multimodal Data:**\n",
    "- SEVIR: Veillette et al., NeurIPS 2020\n",
    "- 4 modalities: VIL, IR069, IR107, GLM\n",
    "- 541 events (432 train / 109 val)\n",
    "\n",
    "**Novel Contributions:**\n",
    "1. GNN-Transformer hybrid for weather nowcasting\n",
    "2. Physics-informed graph construction\n",
    "3. Interpretable attention mechanisms\n",
    "4. Extreme event focus (Stage 4 insights)\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook will be updated as modules are implemented.*\n",
    "*Check git repo for latest code: https://github.com/syedhaliz/stormfusion-sevir*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
