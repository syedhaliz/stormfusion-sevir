{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 05: Test Full Integrated Model\n",
    "\n",
    "**Purpose:** Test the complete SGT model (all 7 components together)\n",
    "\n",
    "**What this does:**\n",
    "- Create the full StormGraphTransformer model\n",
    "- Test end-to-end forward pass\n",
    "- Verify shapes and parameter counts\n",
    "- Test with both dummy data and real SEVIR samples\n",
    "\n",
    "**What this does NOT do:**\n",
    "- Training (that's in notebook 06/07)\n",
    "- Evaluation on full dataset\n",
    "- Hyperparameter tuning\n",
    "\n",
    "**Expected time:** 5 minutes\n",
    "\n",
    "---\n",
    "\n",
    "**Prerequisites:** \n",
    "- Run `01_Setup_and_Environment.ipynb` first\n",
    "- Run `04_Test_Model_Components.ipynb` to verify each module works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import drive\nimport sys\nimport os\nimport torch\nimport torch.nn as nn\n\n# Mount Drive\nprint(\"Mounting Google Drive...\")\ndrive.mount('/content/drive', force_remount=False)\nprint(\"✅ Drive mounted\\n\")\n\n# Install dependencies (each Colab session needs this!)\nprint(\"Installing dependencies...\")\n!pip install -q torch-geometric h5py pandas tqdm matplotlib lpips scikit-image scipy\nprint(\"✅ Dependencies installed\\n\")\n\n# Clone/update repository\nREPO_PATH = '/content/stormfusion-sevir'\nif not os.path.exists(REPO_PATH):\n    print(\"Cloning repository...\")\n    !git clone https://github.com/syedhaliz/stormfusion-sevir.git {REPO_PATH}\n    print(\"✅ Repository cloned\\n\")\nelse:\n    print(\"Repository exists, pulling latest changes...\")\n    !cd {REPO_PATH} && git pull\n    print(\"✅ Repository updated\\n\")\n\n# Add repository to path\nif REPO_PATH not in sys.path:\n    sys.path.insert(0, REPO_PATH)\n    print(f\"✅ Added {REPO_PATH} to Python path\\n\")\n\n# Force reload of modules to get latest code\nimport importlib\nfor module_name in ['stormfusion.models.sgt', 'stormfusion.data.sevir_multimodal']:\n    if module_name in sys.modules:\n        importlib.reload(sys.modules[module_name])\n        \nprint(\"✅ Modules reloaded\\n\")\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\\n\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 2: Create Full SGT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "from stormfusion.models.sgt import create_sgt_model\n\nprint(\"=\"*70)\nprint(\"CREATING FULL STORMGRAPHTRANSFORMER MODEL\")\nprint(\"=\"*70)\n\n# Create model with custom configuration\nconfig = {\n    'modalities': ['vil', 'ir069', 'ir107', 'lght'],\n    'input_steps': 12,\n    'output_steps': 12,  # Predicting 12 future frames\n    'hidden_dim': 128,\n    'gnn_layers': 3,\n    'transformer_layers': 4,\n    'num_heads': 8,\n    'use_physics': True\n}\n\nmodel = create_sgt_model(config).to(device)\n\nprint(\"\\n✅ Model created successfully\")\nprint(f\"   Config: {config}\\n\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 3: Model Architecture Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Count parameters per module\n",
    "print(\"\\nParameters per module:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "modules = [\n",
    "    ('encoder', 'MultiModalEncoder'),\n",
    "    ('detector', 'StormCellDetector'),\n",
    "    ('gnn', 'StormGNN'),\n",
    "    ('transformer', 'SpatioTemporalTransformer'),\n",
    "    ('decoder', 'PhysicsDecoder'),\n",
    "    ('physics_loss', 'ConservationLoss')\n",
    "]\n",
    "\n",
    "total_params = 0\n",
    "for attr_name, module_name in modules:\n",
    "    if hasattr(model, attr_name):\n",
    "        module = getattr(model, attr_name)\n",
    "        params = sum(p.numel() for p in module.parameters())\n",
    "        total_params += params\n",
    "        print(f\"{module_name:30s}: {params:>12,} params\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'TOTAL':30s}: {total_params:>12,} params\")\n",
    "print(f\"{'':30s}  {total_params/1e6:>10.2f} M\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 4: Test Forward Pass (Dummy Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*70)\nprint(\"TEST: FORWARD PASS WITH DUMMY DATA\")\nprint(\"=\"*70)\n\n# Create dummy input (batch_size=2)\nB = 2\ndummy_input = {\n    'vil': torch.randn(B, 12, 384, 384).to(device),\n    'ir069': torch.randn(B, 12, 384, 384).to(device),\n    'ir107': torch.randn(B, 12, 384, 384).to(device),\n    'lght': torch.randn(B, 12, 384, 384).to(device)\n}\n\nprint(\"\\nInput shapes:\")\nfor mod, tensor in dummy_input.items():\n    print(f\"  {mod:8s}: {tuple(tensor.shape)}\")\n\n# Forward pass\ntry:\n    print(\"\\nRunning forward pass...\")\n    with torch.no_grad():\n        # Model returns tuple: (predictions, attention_info, physics_info)\n        output, attention_info, physics_info = model(dummy_input)\n    \n    print(f\"\\n✅ Forward pass successful!\")\n    print(f\"\\nOutput shape: {tuple(output.shape)}\")\n    print(f\"Expected: ({B}, 12, 384, 384)\")\n    \n    # Check statistics\n    print(f\"\\nOutput statistics:\")\n    print(f\"  Min: {output.min().item():.4f}\")\n    print(f\"  Max: {output.max().item():.4f}\")\n    print(f\"  Mean: {output.mean().item():.4f}\")\n    print(f\"  Std: {output.std().item():.4f}\")\n    \n    # Check attention info\n    print(f\"\\nAttention info:\")\n    print(f\"  GNN attention layers: {len(attention_info['gnn_attention'])}\")\n    print(f\"  Transformer attention layers: {len(attention_info['transformer_attention'])}\")\n    \n    # Check physics info\n    if physics_info:\n        print(f\"\\nPhysics info available: {list(physics_info.keys())}\")\n    \n    if output.shape == (B, 12, 384, 384):\n        print(\"\\n✅ Output shape correct!\")\n    else:\n        print(f\"\\n⚠️  Shape mismatch: got {tuple(output.shape)}\")\n    \nexcept Exception as e:\n    print(f\"\\n❌ Error during forward pass: {e}\")\n    import traceback\n    traceback.print_exc()\n\nprint(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 5: Test Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "if torch.cuda.is_available():\n    print(\"=\"*70)\n    print(\"GPU MEMORY USAGE\")\n    print(\"=\"*70)\n    \n    # Clear cache\n    torch.cuda.empty_cache()\n    torch.cuda.reset_peak_memory_stats()\n    \n    # Forward pass (unpack tuple)\n    with torch.no_grad():\n        output, _, _ = model(dummy_input)\n    \n    allocated = torch.cuda.memory_allocated() / 1e9\n    peak = torch.cuda.max_memory_allocated() / 1e9\n    total = torch.cuda.get_device_properties(0).total_memory / 1e9\n    \n    print(f\"\\nMemory usage (inference):\")\n    print(f\"  Current allocated: {allocated:.2f} GB\")\n    print(f\"  Peak allocated: {peak:.2f} GB\")\n    print(f\"  Total GPU memory: {total:.2f} GB\")\n    print(f\"  Usage: {peak/total*100:.1f}%\")\n    \n    if peak < total * 0.8:\n        print(\"\\n✅ Memory usage reasonable\")\n    else:\n        print(\"\\n⚠️  High memory usage - may need smaller batch size\")\n    \n    print(\"\\n\" + \"=\"*70)\nelse:\n    print(\"⏭️  Skipping GPU memory check (no GPU available)\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 6: Test with Real SEVIR Data (Optional)\n",
    "\n",
    "**Only runs if you have SEVIR data from notebook 02**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\n\nDRIVE_ROOT = \"/content/drive/MyDrive/SEVIR_Data\"\nCATALOG_PATH = f\"{DRIVE_ROOT}/data/SEVIR_CATALOG.csv\"\n\n# Check if data exists\nif Path(CATALOG_PATH).exists():\n    print(\"=\"*70)\n    print(\"TEST: FORWARD PASS WITH REAL SEVIR DATA\")\n    print(\"=\"*70)\n    \n    try:\n        # Import dataset\n        from stormfusion.data.sevir_multimodal import SEVIRMultiModalDataset\n        import pandas as pd\n        \n        # Load catalog\n        catalog = pd.read_csv(CATALOG_PATH, low_memory=False)\n        \n        # Get small subset of events (just pick first 2 unique event IDs)\n        all_events = catalog['id'].unique()\n        train_events = all_events[:2]\n        \n        print(f\"\\nLoading {len(train_events)} events for testing...\")\n        print(f\"Event IDs: {train_events}\")\n        \n        # Create dataset\n        dataset = SEVIRMultiModalDataset(\n            catalog=catalog,\n            data_root=f\"{DRIVE_ROOT}/data/sevir\",\n            event_ids=train_events,\n            input_steps=12,\n            output_steps=12,\n            modalities=['vil', 'ir069', 'ir107', 'lght']\n        )\n        \n        print(f\"Dataset size: {len(dataset)}\")\n        \n        # Load one sample\n        print(\"\\nLoading first sample...\")\n        inputs, targets = dataset[0]\n        \n        print(\"\\nInput shapes:\")\n        for mod, data in inputs.items():\n            print(f\"  {mod:8s}: {tuple(data.shape)}\")\n            if data.abs().sum() < 0.01:\n                print(f\"    ⚠️  All zeros (missing modality)\")\n        \n        print(f\"\\nTarget shape: {tuple(targets.shape)}\")\n        \n        # Add batch dimension and move to device\n        batch_inputs = {k: v.unsqueeze(0).to(device) for k, v in inputs.items()}\n        \n        # Forward pass (unpack tuple)\n        print(\"\\nRunning forward pass with real data...\")\n        with torch.no_grad():\n            real_output, real_attention, real_physics = model(batch_inputs)\n        \n        print(f\"\\n✅ Forward pass with real data successful!\")\n        print(f\"Output shape: {tuple(real_output.shape)}\")\n        \n        # Statistics\n        print(f\"\\nOutput statistics:\")\n        print(f\"  Min: {real_output.min().item():.4f}\")\n        print(f\"  Max: {real_output.max().item():.4f}\")\n        print(f\"  Mean: {real_output.mean().item():.4f}\")\n        print(f\"  Std: {real_output.std().item():.4f}\")\n        \n    except Exception as e:\n        print(f\"\\n⚠️  Could not test with real data: {e}\")\n        import traceback\n        traceback.print_exc()\n        print(\"\\n   This is OK - the model still works with dummy data\")\n    \n    print(\"\\n\" + \"=\"*70)\nelse:\n    print(\"⏭️  Skipping real data test (no SEVIR catalog found)\")\n    print(f\"   Run notebook 02 to download data first\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 7: Test Gradient Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*70)\nprint(\"TEST: GRADIENT FLOW (BACKPROPAGATION)\")\nprint(\"=\"*70)\n\n# Create optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n# Forward pass (unpack tuple)\noutput, attention_info, physics_info = model(dummy_input)\n\n# Create dummy target\ntarget = torch.randn_like(output)\n\n# Compute loss using model's compute_loss method\nloss, loss_dict = model.compute_loss(\n    predictions=output,\n    targets=target,\n    physics_info=physics_info,\n    lambda_mse=1.0,\n    lambda_physics=0.1,\n    lambda_extreme=2.0\n)\n\nprint(f\"\\nLoss value: {loss.item():.6f}\")\nprint(f\"\\nLoss breakdown:\")\nfor key, value in loss_dict.items():\n    print(f\"  {key}: {value:.6f}\")\n\n# Backward pass\ntry:\n    print(\"\\nRunning backward pass...\")\n    optimizer.zero_grad()\n    loss.backward()\n    \n    # Check gradients\n    has_gradients = False\n    nan_gradients = False\n    \n    for name, param in model.named_parameters():\n        if param.grad is not None:\n            has_gradients = True\n            if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():\n                nan_gradients = True\n                print(f\"  ⚠️  NaN/Inf gradient in: {name}\")\n    \n    if has_gradients and not nan_gradients:\n        print(\"\\n✅ Gradients computed successfully!\")\n        print(\"   Model is ready for training\")\n    elif nan_gradients:\n        print(\"\\n⚠️  NaN/Inf gradients detected - may need gradient clipping\")\n    else:\n        print(\"\\n⚠️  No gradients found\")\n    \nexcept Exception as e:\n    print(f\"\\n❌ Error during backward pass: {e}\")\n    import traceback\n    traceback.print_exc()\n\nprint(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we verified:**\n",
    "- ✅ Full SGT model can be created (~5.3M parameters)\n",
    "- ✅ Forward pass works with dummy data\n",
    "- ✅ Output shapes are correct\n",
    "- ✅ Memory usage is reasonable\n",
    "- ✅ Gradient flow works (backpropagation)\n",
    "- ✅ (Optional) Works with real SEVIR data\n",
    "\n",
    "**Model specification:**\n",
    "```\n",
    "Input:  4 modalities × 12 frames × 384×384\n",
    "Output: 1 modality × 12 frames × 384×384\n",
    "Parameters: ~5.3M\n",
    "Memory: ~X.X GB (inference)\n",
    "```\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "MultiModalEncoder (4 modalities → unified)\n",
    "    ↓\n",
    "StormCellDetector (spatial → graph)\n",
    "    ↓\n",
    "StormGNN (message passing)\n",
    "    ↓\n",
    "SpatioTemporalTransformer (attention)\n",
    "    ↓\n",
    "PhysicsDecoder (features → predictions)\n",
    "    ↓\n",
    "ConservationLoss (physics constraints)\n",
    "```\n",
    "\n",
    "**Next steps:**\n",
    "1. If all tests passed ✅, proceed to `06_Small_Scale_Training.ipynb`\n",
    "2. That notebook will train on a small subset (10-20 events)\n",
    "3. Verify training works before scaling to full dataset\n",
    "\n",
    "---\n",
    "\n",
    "**If any test failed:**\n",
    "- Go back to `04_Test_Model_Components.ipynb`\n",
    "- Identify which component has issues\n",
    "- Check error messages and tracebacks\n",
    "- Verify all dependencies are installed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}