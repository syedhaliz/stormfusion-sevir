{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 05: Test Full Integrated Model\n",
    "\n",
    "**Purpose:** Test the complete SGT model (all 7 components together)\n",
    "\n",
    "**What this does:**\n",
    "- Create the full StormGraphTransformer model\n",
    "- Test end-to-end forward pass\n",
    "- Verify shapes and parameter counts\n",
    "- Test with both dummy data and real SEVIR samples\n",
    "\n",
    "**What this does NOT do:**\n",
    "- Training (that's in notebook 06/07)\n",
    "- Evaluation on full dataset\n",
    "- Hyperparameter tuning\n",
    "\n",
    "**Expected time:** 5 minutes\n",
    "\n",
    "---\n",
    "\n",
    "**Prerequisites:** \n",
    "- Run `01_Setup_and_Environment.ipynb` first\n",
    "- Run `04_Test_Model_Components.ipynb` to verify each module works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "# Add repository to path\n",
    "REPO_PATH = '/content/stormfusion-sevir'\n",
    "if REPO_PATH not in sys.path:\n",
    "    sys.path.insert(0, REPO_PATH)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 2: Create Full SGT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stormfusion.models.sgt import create_sgt_model\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CREATING FULL STORMGRAPHTRANSFORMER MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create model with default configuration\n",
    "model = create_sgt_model(\n",
    "    modalities=['vil', 'ir069', 'ir107', 'lght'],\n",
    "    input_steps=12,\n",
    "    output_steps=12,\n",
    "    base_channels=64\n",
    ").to(device)\n",
    "\n",
    "print(\"\\n✅ Model created successfully\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 3: Model Architecture Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Count parameters per module\n",
    "print(\"\\nParameters per module:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "modules = [\n",
    "    ('encoder', 'MultiModalEncoder'),\n",
    "    ('detector', 'StormCellDetector'),\n",
    "    ('gnn', 'StormGNN'),\n",
    "    ('transformer', 'SpatioTemporalTransformer'),\n",
    "    ('decoder', 'PhysicsDecoder'),\n",
    "    ('physics_loss', 'ConservationLoss')\n",
    "]\n",
    "\n",
    "total_params = 0\n",
    "for attr_name, module_name in modules:\n",
    "    if hasattr(model, attr_name):\n",
    "        module = getattr(model, attr_name)\n",
    "        params = sum(p.numel() for p in module.parameters())\n",
    "        total_params += params\n",
    "        print(f\"{module_name:30s}: {params:>12,} params\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'TOTAL':30s}: {total_params:>12,} params\")\n",
    "print(f\"{'':30s}  {total_params/1e6:>10.2f} M\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 4: Test Forward Pass (Dummy Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TEST: FORWARD PASS WITH DUMMY DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create dummy input (batch_size=2)\n",
    "B = 2\n",
    "dummy_input = {\n",
    "    'vil': torch.randn(B, 12, 384, 384).to(device),\n",
    "    'ir069': torch.randn(B, 12, 384, 384).to(device),\n",
    "    'ir107': torch.randn(B, 12, 384, 384).to(device),\n",
    "    'lght': torch.randn(B, 12, 384, 384).to(device)\n",
    "}\n",
    "\n",
    "print(\"\\nInput shapes:\")\n",
    "for mod, tensor in dummy_input.items():\n",
    "    print(f\"  {mod:8s}: {tuple(tensor.shape)}\")\n",
    "\n",
    "# Forward pass\n",
    "try:\n",
    "    print(\"\\nRunning forward pass...\")\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input)\n",
    "    \n",
    "    print(f\"\\n✅ Forward pass successful!\")\n",
    "    print(f\"\\nOutput shape: {tuple(output.shape)}\")\n",
    "    print(f\"Expected: ({B}, 12, 384, 384)\")\n",
    "    \n",
    "    # Check statistics\n",
    "    print(f\"\\nOutput statistics:\")\n",
    "    print(f\"  Min: {output.min().item():.4f}\")\n",
    "    print(f\"  Max: {output.max().item():.4f}\")\n",
    "    print(f\"  Mean: {output.mean().item():.4f}\")\n",
    "    print(f\"  Std: {output.std().item():.4f}\")\n",
    "    \n",
    "    if output.shape == (B, 12, 384, 384):\n",
    "        print(\"\\n✅ Output shape correct!\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️  Shape mismatch: got {tuple(output.shape)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error during forward pass: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 5: Test Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"=\"*70)\n",
    "    print(\"GPU MEMORY USAGE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Clear cache\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input)\n",
    "    \n",
    "    allocated = torch.cuda.memory_allocated() / 1e9\n",
    "    peak = torch.cuda.max_memory_allocated() / 1e9\n",
    "    total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    \n",
    "    print(f\"\\nMemory usage (inference):\")\n",
    "    print(f\"  Current allocated: {allocated:.2f} GB\")\n",
    "    print(f\"  Peak allocated: {peak:.2f} GB\")\n",
    "    print(f\"  Total GPU memory: {total:.2f} GB\")\n",
    "    print(f\"  Usage: {peak/total*100:.1f}%\")\n",
    "    \n",
    "    if peak < total * 0.8:\n",
    "        print(\"\\n✅ Memory usage reasonable\")\n",
    "    else:\n",
    "        print(\"\\n⚠️  High memory usage - may need smaller batch size\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\nelse:\n",
    "    print(\"⏭️  Skipping GPU memory check (no GPU available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 6: Test with Real SEVIR Data (Optional)\n",
    "\n",
    "**Only runs if you have SEVIR data from notebook 02**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive/SEVIR_Data\"\n",
    "CATALOG_PATH = f\"{DRIVE_ROOT}/data/SEVIR_CATALOG.csv\"\n",
    "\n",
    "# Check if data exists\n",
    "if Path(CATALOG_PATH).exists():\n",
    "    print(\"=\"*70)\n",
    "    print(\"TEST: FORWARD PASS WITH REAL SEVIR DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        # Import dataset\n",
    "        from stormfusion.data.sevir_multimodal import SEVIRMultiModalDataset\n",
    "        import pandas as pd\n",
    "        \n",
    "        # Load catalog\n",
    "        catalog = pd.read_csv(CATALOG_PATH, low_memory=False)\n",
    "        \n",
    "        # Get small subset\n",
    "        train_events = catalog[catalog['split'] == 'train']['id'].unique()[:2]\n",
    "        \n",
    "        print(f\"\\nLoading {len(train_events)} training events...\")\n",
    "        \n",
    "        # Create dataset\n",
    "        dataset = SEVIRMultiModalDataset(\n",
    "            catalog=catalog,\n",
    "            data_root=f\"{DRIVE_ROOT}/data/sevir\",\n",
    "            event_ids=train_events,\n",
    "            input_steps=12,\n",
    "            output_steps=12,\n",
    "            modalities=['vil', 'ir069', 'ir107', 'lght']\n",
    "        )\n",
    "        \n",
    "        print(f\"Dataset size: {len(dataset)}\")\n",
    "        \n",
    "        # Load one sample\n",
    "        print(\"\\nLoading first sample...\")\n",
    "        inputs, targets = dataset[0]\n",
    "        \n",
    "        print(\"\\nInput shapes:\")\n",
    "        for mod, data in inputs.items():\n",
    "            print(f\"  {mod:8s}: {tuple(data.shape)}\")\n",
    "            if data.abs().sum() < 0.01:\n",
    "                print(f\"    ⚠️  All zeros (missing modality)\")\n",
    "        \n",
    "        print(f\"\\nTarget shape: {tuple(targets.shape)}\")\n",
    "        \n",
    "        # Add batch dimension and move to device\n",
    "        batch_inputs = {k: v.unsqueeze(0).to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        print(\"\\nRunning forward pass with real data...\")\n",
    "        with torch.no_grad():\n",
    "            real_output = model(batch_inputs)\n",
    "        \n",
    "        print(f\"\\n✅ Forward pass with real data successful!\")\n",
    "        print(f\"Output shape: {tuple(real_output.shape)}\")\n",
    "        \n",
    "        # Statistics\n",
    "        print(f\"\\nOutput statistics:\")\n",
    "        print(f\"  Min: {real_output.min().item():.4f}\")\n",
    "        print(f\"  Max: {real_output.max().item():.4f}\")\n",
    "        print(f\"  Mean: {real_output.mean().item():.4f}\")\n",
    "        print(f\"  Std: {real_output.std().item():.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠️  Could not test with real data: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"\\n   This is OK - the model still works with dummy data\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "else:\n",
    "    print(\"⏭️  Skipping real data test (no SEVIR catalog found)\")\n",
    "    print(f\"   Run notebook 02 to download data first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 7: Test Gradient Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TEST: GRADIENT FLOW (BACKPROPAGATION)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Forward pass\n",
    "output = model(dummy_input)\n",
    "\n",
    "# Create dummy target\n",
    "target = torch.randn_like(output)\n",
    "\n",
    "# Compute loss\n",
    "loss = nn.MSELoss()(output, target)\n",
    "print(f\"\\nLoss value: {loss.item():.6f}\")\n",
    "\n",
    "# Backward pass\n",
    "try:\n",
    "    print(\"\\nRunning backward pass...\")\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Check gradients\n",
    "    has_gradients = False\n",
    "    nan_gradients = False\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            has_gradients = True\n",
    "            if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():\n",
    "                nan_gradients = True\n",
    "                print(f\"  ⚠️  NaN/Inf gradient in: {name}\")\n",
    "    \n",
    "    if has_gradients and not nan_gradients:\n",
    "        print(\"\\n✅ Gradients computed successfully!\")\n",
    "        print(\"   Model is ready for training\")\n",
    "    elif nan_gradients:\n",
    "        print(\"\\n⚠️  NaN/Inf gradients detected - may need gradient clipping\")\n",
    "    else:\n",
    "        print(\"\\n⚠️  No gradients found\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error during backward pass: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we verified:**\n",
    "- ✅ Full SGT model can be created (~5.3M parameters)\n",
    "- ✅ Forward pass works with dummy data\n",
    "- ✅ Output shapes are correct\n",
    "- ✅ Memory usage is reasonable\n",
    "- ✅ Gradient flow works (backpropagation)\n",
    "- ✅ (Optional) Works with real SEVIR data\n",
    "\n",
    "**Model specification:**\n",
    "```\n",
    "Input:  4 modalities × 12 frames × 384×384\n",
    "Output: 1 modality × 12 frames × 384×384\n",
    "Parameters: ~5.3M\n",
    "Memory: ~X.X GB (inference)\n",
    "```\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "MultiModalEncoder (4 modalities → unified)\n",
    "    ↓\n",
    "StormCellDetector (spatial → graph)\n",
    "    ↓\n",
    "StormGNN (message passing)\n",
    "    ↓\n",
    "SpatioTemporalTransformer (attention)\n",
    "    ↓\n",
    "PhysicsDecoder (features → predictions)\n",
    "    ↓\n",
    "ConservationLoss (physics constraints)\n",
    "```\n",
    "\n",
    "**Next steps:**\n",
    "1. If all tests passed ✅, proceed to `06_Small_Scale_Training.ipynb`\n",
    "2. That notebook will train on a small subset (10-20 events)\n",
    "3. Verify training works before scaling to full dataset\n",
    "\n",
    "---\n",
    "\n",
    "**If any test failed:**\n",
    "- Go back to `04_Test_Model_Components.ipynb`\n",
    "- Identify which component has issues\n",
    "- Check error messages and tracebacks\n",
    "- Verify all dependencies are installed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
