{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03: Test Data Loader\n",
    "\n",
    "**Purpose:** Test the dataset and data loading pipeline\n",
    "\n",
    "**What this does:**\n",
    "- Load event IDs\n",
    "- Build dataset index\n",
    "- Test loading a few samples\n",
    "- Verify data shapes and ranges\n",
    "- Test augmentation\n",
    "- Test batching\n",
    "\n",
    "**What this does NOT do:**\n",
    "- Create models\n",
    "- Run training\n",
    "- Load all data (only a few samples for testing)\n",
    "\n",
    "**Expected time:** 2-3 minutes\n",
    "\n",
    "---\n",
    "\n",
    "**Prerequisites:**\n",
    "1. Run `01_Setup_and_Environment.ipynb`\n",
    "2. Run `02_Data_Verification.ipynb` and ensure data exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import drive\nimport sys\nimport os\nimport torch\n\n# Mount Drive\nprint(\"Mounting Google Drive...\")\ndrive.mount('/content/drive', force_remount=False)\nprint(\"✅ Drive mounted\\n\")\n\n# Add repo to path\nsys.path.insert(0, '/content/stormfusion-sevir')\n\n# Paths\nDRIVE_ROOT = \"/content/drive/MyDrive/SEVIR_Data\"\nSEVIR_ROOT = f\"{DRIVE_ROOT}/data/sevir\"\nCATALOG_PATH = f\"{DRIVE_ROOT}/data/SEVIR_CATALOG.csv\"\nTRAIN_IDS = f\"{DRIVE_ROOT}/data/samples/all_train_ids.txt\"\nVAL_IDS = f\"{DRIVE_ROOT}/data/samples/all_val_ids.txt\"\n\nprint(\"Paths configured:\")\nprint(f\"  SEVIR_ROOT: {SEVIR_ROOT}\")\nprint(f\"  Catalog exists: {os.path.exists(CATALOG_PATH)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stormfusion.data.sevir_multimodal import (\n",
    "    SEVIRMultiModalDataset,\n",
    "    build_multimodal_index,\n",
    "    multimodal_collate_fn\n",
    ")\n",
    "\n",
    "print(\"✅ Dataset class imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build Index (Test with Small Subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building dataset index...\\n\")\n",
    "\n",
    "# Build full index first to see how many events we have\n",
    "train_index_full = build_multimodal_index(CATALOG_PATH, TRAIN_IDS, SEVIR_ROOT)\n",
    "val_index_full = build_multimodal_index(CATALOG_PATH, VAL_IDS, SEVIR_ROOT)\n",
    "\n",
    "print(f\"\\nFull dataset:\")\n",
    "print(f\"  Train: {len(train_index_full)} events\")\n",
    "print(f\"  Val: {len(val_index_full)} events\")\n",
    "\n",
    "# For testing, use only first 10 events\n",
    "train_index = train_index_full[:10]\n",
    "val_index = val_index_full[:5]\n",
    "\n",
    "print(f\"\\nTest subset:\")\n",
    "print(f\"  Train: {len(train_index)} events\")\n",
    "print(f\"  Val: {len(val_index)} events\")\n",
    "print(f\"\\n✅ Index built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Dataset (Small Subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating test dataset...\")\n",
    "\n",
    "test_dataset = SEVIRMultiModalDataset(\n",
    "    train_index,  # Only 10 events\n",
    "    sevir_root=SEVIR_ROOT,\n",
    "    catalog_path=CATALOG_PATH,\n",
    "    input_steps=12,\n",
    "    output_steps=6,\n",
    "    normalize=True,\n",
    "    augment=False  # No augmentation for testing\n",
    ")\n",
    "\n",
    "print(f\"✅ Dataset created with {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Load and Inspect Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading sample 0...\\n\")\n",
    "\n",
    "inputs, outputs = test_dataset[0]\n",
    "\n",
    "print(\"INPUT SHAPES:\")\n",
    "for modality, data in inputs.items():\n",
    "    print(f\"  {modality:8s}: {tuple(data.shape):20s} (T, H, W)\")\n",
    "    print(f\"             Range: [{data.min():.3f}, {data.max():.3f}]\")\n",
    "    print(f\"             Mean: {data.mean():.3f}, Std: {data.std():.3f}\")\n",
    "    \n",
    "    # Check for zeros (indicates missing data)\n",
    "    if data.abs().sum() < 0.01:\n",
    "        print(f\"             ⚠️  WARNING: All zeros (missing modality)\")\n",
    "    print()\n",
    "\n",
    "print(\"OUTPUT SHAPES:\")\n",
    "for modality, data in outputs.items():\n",
    "    print(f\"  {modality:8s}: {tuple(data.shape):20s} (T, H, W)\")\n",
    "    print(f\"             Range: [{data.min():.3f}, {data.max():.3f}]\")\n",
    "    print()\n",
    "\n",
    "print(\"✅ Sample loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Show last input frame for each modality\n",
    "for i, modality in enumerate(['vil', 'ir069', 'ir107', 'lght']):\n",
    "    data = inputs[modality][-1].numpy()  # Last timestep\n",
    "    im = axes[0, i].imshow(data, cmap='viridis', vmin=data.min(), vmax=data.max())\n",
    "    axes[0, i].set_title(f'{modality.upper()}\\n(input t=12)')\n",
    "    axes[0, i].axis('off')\n",
    "    plt.colorbar(im, ax=axes[0, i], fraction=0.046)\n",
    "\n",
    "# Show VIL predictions (first 4 output timesteps)\n",
    "for i in range(4):\n",
    "    if i < outputs['vil'].shape[0]:\n",
    "        data = outputs['vil'][i].numpy()\n",
    "        im = axes[1, i].imshow(data, cmap='viridis', vmin=0, vmax=1)\n",
    "        axes[1, i].set_title(f'VIL Target\\n(t+{(i+1)*5}min)')\n",
    "        axes[1, i].axis('off')\n",
    "        plt.colorbar(im, ax=axes[1, i], fraction=0.046)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/sample_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved to /content/sample_visualization.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test Multiple Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading multiple samples...\\n\")\n",
    "\n",
    "num_samples = min(5, len(test_dataset))\n",
    "\n",
    "for idx in range(num_samples):\n",
    "    try:\n",
    "        inputs, outputs = test_dataset[idx]\n",
    "        print(f\"Sample {idx}: ✅ shapes correct\")\n",
    "    except Exception as e:\n",
    "        print(f\"Sample {idx}: ❌ Error: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Successfully loaded {num_samples} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Test DataLoader with Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"Creating DataLoader...\\n\")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    collate_fn=multimodal_collate_fn\n",
    ")\n",
    "\n",
    "print(f\"DataLoader created: {len(test_loader)} batches\\n\")\n",
    "\n",
    "# Test loading one batch\n",
    "print(\"Loading first batch...\")\n",
    "inputs_batch, outputs_batch = next(iter(test_loader))\n",
    "\n",
    "print(\"\\nBatch shapes:\")\n",
    "print(\"  Inputs:\")\n",
    "for modality, data in inputs_batch.items():\n",
    "    print(f\"    {modality:8s}: {tuple(data.shape):25s} (B, T, H, W)\")\n",
    "\n",
    "print(\"  Outputs:\")\n",
    "for modality, data in outputs_batch.items():\n",
    "    print(f\"    {modality:8s}: {tuple(data.shape):25s} (B, T, H, W)\")\n",
    "\n",
    "print(\"\\n✅ Batching works correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Test Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing augmentation...\\n\")\n",
    "\n",
    "# Create dataset with augmentation\n",
    "aug_dataset = SEVIRMultiModalDataset(\n",
    "    train_index[:5],\n",
    "    sevir_root=SEVIR_ROOT,\n",
    "    catalog_path=CATALOG_PATH,\n",
    "    input_steps=12,\n",
    "    output_steps=6,\n",
    "    normalize=True,\n",
    "    augment=True  # Enable augmentation\n",
    ")\n",
    "\n",
    "# Load same sample multiple times to see augmentation\n",
    "print(\"Loading same sample 3 times with augmentation:\\n\")\n",
    "for i in range(3):\n",
    "    inputs, outputs = aug_dataset[0]\n",
    "    vil_sum = inputs['vil'].sum().item()\n",
    "    print(f\"  Iteration {i+1}: VIL sum = {vil_sum:.2f} (should vary due to flips/rotations)\")\n",
    "\n",
    "print(\"\\n✅ Augmentation working (values change between iterations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**What we tested:**\n",
    "- ✅ Dataset index building\n",
    "- ✅ Single sample loading\n",
    "- ✅ Data shapes are correct\n",
    "- ✅ Normalization applied\n",
    "- ✅ Batching works\n",
    "- ✅ Augmentation works\n",
    "\n",
    "**Warnings to check:**\n",
    "- If you see \"All zeros\" warnings, those modalities are missing from your data\n",
    "- Model will still run but use zeros for those channels\n",
    "- Download complete data for best performance\n",
    "\n",
    "**Next notebook:** `04_Test_Model_Components.ipynb`  \n",
    "This will test each model module individually before full integration."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}