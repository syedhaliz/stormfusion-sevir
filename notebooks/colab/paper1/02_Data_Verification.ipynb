{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_s4D2UuNlXn"
   },
   "source": [
    "# 02: Data Verification and Download\n",
    "\n",
    "**Purpose:** Check what SEVIR data you have and download missing files\n",
    "\n",
    "**What this does:**\n",
    "- Check which SEVIR modalities exist\n",
    "- Count files per modality\n",
    "- Identify missing data\n",
    "- Provide download instructions/scripts\n",
    "\n",
    "**What this does NOT do:**\n",
    "- Load actual data into memory\n",
    "- Create models\n",
    "- Run training\n",
    "\n",
    "**Expected time:** 5 minutes (or 30-90 min if downloading data)\n",
    "\n",
    "---\n",
    "\n",
    "**Prerequisites:** Run `01_Setup_and_Environment.ipynb` first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_O58iWnNlXo"
   },
   "source": [
    "## Step 1: Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5sGys8tNlXo",
    "outputId": "7cefd5ad-02e5-4dd5-c85c-09444e7ccd1e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": "from google.colab import drive\nimport os\nimport glob\nimport pandas as pd\n\n# Mount Google Drive FIRST\nprint(\"Mounting Google Drive...\")\ndrive.mount('/content/drive', force_remount=False)\nprint(\"‚úÖ Drive mounted\\n\")\n\n# Your data directory (should match from 01_Setup)\nDRIVE_ROOT = \"/content/drive/MyDrive/SEVIR_Data\"\nSEVIR_ROOT = f\"{DRIVE_ROOT}/data/sevir\"\nCATALOG_PATH = f\"{DRIVE_ROOT}/data/SEVIR_CATALOG.csv\"\n\nprint(f\"SEVIR root: {SEVIR_ROOT}\")\nprint(f\"Catalog: {CATALOG_PATH}\")\n\n# Verify paths exist\nprint(f\"\\nVerifying paths...\")\nprint(f\"SEVIR_Data exists: {os.path.exists(DRIVE_ROOT)}\")\nprint(f\"sevir folder exists: {os.path.exists(SEVIR_ROOT)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7AIQjCyNlXo"
   },
   "source": [
    "## Step 2: Check What Data Files Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edgrK2WONlXp",
    "outputId": "7c1aa526-abb5-4918-bbaf-4cebb619d2aa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": "print(\"=\"*70)\nprint(\"SEVIR DATA CHECK\")\nprint(\"=\"*70)\n\nmodalities = {\n    'vil': 'VIL (Radar) - TARGET MODALITY',\n    'ir069': 'GOES-16 C09 (Water Vapor 6.9Œºm)',\n    'ir107': 'GOES-16 C13 (IR Window 10.7Œºm)',\n    'lght': 'GOES-16 GLM (Lightning)'\n}\n\n# Expected file counts per year (from AWS S3)\nexpected_counts_2019 = {\n    'vil': 5,\n    'ir069': 5,\n    'ir107': 5,\n    'lght': 11\n}\n\n# Years to check (add more years as needed)\nyears_to_check = ['2019', '2018', '2017']\n\ndata_status = {}\n\nfor year in years_to_check:\n    print(f\"\\n{'='*70}\")\n    print(f\"YEAR {year}\")\n    print(f\"{'='*70}\")\n    \n    year_data = {}\n    \n    for mod, desc in modalities.items():\n        mod_path = f\"{SEVIR_ROOT}/{mod}/{year}\"\n        \n        if os.path.exists(mod_path):\n            h5_files = glob.glob(f\"{mod_path}/*.h5\")\n            total_gb = sum(os.path.getsize(f) for f in h5_files) / 1e9\n            \n            expected = expected_counts_2019.get(mod, 5)  # Default to 5 if not specified\n            # Complete if we have at least 1 file (be lenient)\n            status = \"‚úÖ\" if len(h5_files) > 0 else \"‚ùå\"\n            \n            print(f\"{status} {mod.upper():8s}: {len(h5_files):3d} files ({total_gb:.1f} GB)\")\n            \n            year_data[mod] = {\n                'exists': True,\n                'files': len(h5_files),\n                'size_gb': total_gb,\n                'complete': len(h5_files) > 0\n            }\n        else:\n            print(f\"‚ùå {mod.upper():8s}: NOT FOUND\")\n            \n            year_data[mod] = {\n                'exists': False,\n                'files': 0,\n                'size_gb': 0,\n                'complete': False\n            }\n    \n    data_status[year] = year_data\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"SUMMARY\")\nprint(\"=\"*70)\n\nfor year in years_to_check:\n    total_files = sum(d['files'] for d in data_status[year].values())\n    total_gb = sum(d['size_gb'] for d in data_status[year].values())\n    print(f\"{year}: {total_files:3d} files, {total_gb:6.1f} GB\")\n\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT8FiAALNlXp"
   },
   "source": [
    "## Step 3: Check Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNzLBzfUNlXp",
    "outputId": "786dc08b-4205-4486-f729-9f0b5a10345a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": "# Load catalog if it exists\nif os.path.exists(CATALOG_PATH):\n    catalog = pd.read_csv(CATALOG_PATH, low_memory=False)\n\n    print(\"üìã SEVIR Catalog Analysis\\n\")\n\n    for mod in ['vil', 'ir069', 'ir107', 'lght']:\n        mod_catalog = catalog[catalog['img_type'] == mod]\n        unique_files = mod_catalog['file_name'].nunique()\n        unique_events = mod_catalog['id'].nunique()\n\n        print(f\"{mod.upper():8s}:\")\n        print(f\"  Catalog lists {unique_files} files\")\n        print(f\"  Catalog lists {unique_events} events\")\n\n        # Count total files we have across all years\n        total_files = 0\n        for year in years_to_check:\n            if year in data_status and mod in data_status[year]:\n                total_files += data_status[year][mod]['files']\n        \n        if total_files > 0:\n            coverage = (total_files / unique_files * 100) if unique_files > 0 else 0\n            print(f\"  You have {total_files} files across all years ({coverage:.1f}% coverage)\")\n        else:\n            print(f\"  You have 0 files\")\n        print()\nelse:\n    print(f\"‚ùå Catalog not found: {CATALOG_PATH}\")\n    print(\"   Download from: https://sevir.mit.edu/\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPhwpEvfNlXp"
   },
   "source": [
    "## Step 4: Data Completeness Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSXACt0hNlXp",
    "outputId": "87dd9785-7423-4b6a-840f-844701779899",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": "print(\"=\"*70)\nprint(\"DATA COMPLETENESS ASSESSMENT\")\nprint(\"=\"*70)\n\n# Check completeness for each year\nany_vil_data = False\nall_years_complete = True\n\nfor year in years_to_check:\n    year_status = data_status[year]\n    vil_exists = year_status['vil']['complete']\n    all_mods_exist = all(status['complete'] for status in year_status.values())\n    \n    if vil_exists:\n        any_vil_data = True\n    \n    if not all_mods_exist:\n        all_years_complete = False\n    \n    status_emoji = \"‚úÖ\" if all_mods_exist else (\"‚ö†Ô∏è\" if vil_exists else \"‚ùå\")\n    print(f\"\\n{status_emoji} {year}: VIL={'‚úÖ' if vil_exists else '‚ùå'}, All={'‚úÖ' if all_mods_exist else '‚ùå'}\")\n\nprint(\"\\n\" + \"=\"*70)\n\nif any_vil_data:\n    print(\"\\n‚úÖ GOOD: Have VIL data for at least one year\")\n    print(\"   Can proceed with training\")\n    \n    if not all_years_complete:\n        print(\"\\n‚ö†Ô∏è  Some years/modalities incomplete\")\n        print(\"   Can train, but performance may be degraded\")\n        print(\"   Recommendation: Download missing data for best results\")\n    \n    need_download = not all_years_complete\nelse:\n    print(\"\\n‚ùå CRITICAL: No VIL data found\")\n    print(\"   VIL is the TARGET modality - training will fail without it\")\n    print(\"   Action Required: Download VIL data\")\n    need_download = True\n\nprint(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeqQNEg4NlXp"
   },
   "source": [
    "## Step 5: Download Data (If Needed)\n",
    "\n",
    "**Set `DOWNLOAD = True` to enable download**\n",
    "\n",
    "**WARNING:** This will download ~50 GB and take 30-90 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lp90exmoNlXp"
   },
   "outputs": [],
   "source": "DOWNLOAD = False  # ‚ö†Ô∏è SET TO True TO DOWNLOAD\n\n# Specify which years to download (edit this list!)\nYEARS_TO_DOWNLOAD = ['2018', '2017']  # 2019 already exists\n\nif DOWNLOAD and need_download:\n    print(\"=\"*70)\n    print(\"DOWNLOADING SEVIR DATA FROM AWS S3\")\n    print(\"=\"*70)\n    print(f\"\\nWill download years: {YEARS_TO_DOWNLOAD}\")\n    print(\"\\n‚ÑπÔ∏è  Note: Per year, AWS S3 contains:\")\n    print(\"   - VIL: ~60 GB (5 files)\")\n    print(\"   - IR069: ~25 GB (5 files)\")\n    print(\"   - IR107: ~25 GB (5 files)\")\n    print(\"   - LGHT: ~1 GB (11 files)\")\n    print(\"   Total per year: ~110 GB\\n\")\n    \n    # Install AWS CLI\n    print(\"Installing AWS CLI...\")\n    !pip install -q awscli\n    print(\"‚úÖ AWS CLI ready\\n\")\n    \n    # Download each year and modality\n    for year in YEARS_TO_DOWNLOAD:\n        print(f\"\\n{'='*70}\")\n        print(f\"DOWNLOADING YEAR {year}\")\n        print(f\"{'='*70}\")\n        \n        year_status = data_status.get(year, {})\n        \n        for mod in ['vil', 'ir069', 'ir107', 'lght']:\n            mod_status = year_status.get(mod, {'complete': False})\n            \n            # Skip if already have files\n            if mod_status['complete'] and mod_status['files'] > 0:\n                print(f\"\\n‚úÖ {mod.upper():8s} ({year}): Already have {mod_status['files']} files, skipping\")\n                continue\n            \n            print(f\"\\n‚¨áÔ∏è  {mod.upper():8s} ({year}): Starting download...\")\n            \n            target_dir = f\"{SEVIR_ROOT}/{mod}/{year}\"\n            \n            # Create directory\n            !mkdir -p \"{target_dir}\"\n            \n            # Download with sync (only downloads what's missing!)\n            !aws s3 sync s3://sevir/data/{mod}/{year}/ \"{target_dir}\" --no-sign-request --region us-east-1\n            \n            # Verify what we have now\n            files = glob.glob(f\"{target_dir}/*.h5\")\n            total_gb = sum(os.path.getsize(f) for f in files) / 1e9\n            print(f\"   ‚úÖ Now have {len(files)} files ({total_gb:.1f} GB) for {mod}/{year}\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"‚úÖ DOWNLOAD COMPLETE\")\n    print(\"=\"*70)\n    print(\"\\nüìã RECOMMENDED: Re-run Step 2 (cell above) to verify all downloads\")\n    \nelif not DOWNLOAD:\n    print(\"‚è≠Ô∏è  Download skipped\")\n    print(\"\\nüìù To download:\")\n    print(\"   1. Edit YEARS_TO_DOWNLOAD list above (remove years you already have)\")\n    print(\"   2. Set DOWNLOAD=True\")\n    print(\"   3. Re-run this cell\")\n    \n    if need_download:\n        print(\"\\n‚ö†Ô∏è  You have incomplete data\")\n        print(f\"   Years to download: {YEARS_TO_DOWNLOAD}\")\nelse:\n    print(\"‚úÖ Data already complete, no download needed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXhOBfrbNlXp"
   },
   "source": [
    "## Step 6: Sample a Few Files (Sanity Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cie1oh20NlXp"
   },
   "outputs": [],
   "source": "import h5py\nimport numpy as np\n\nprint(\"Testing file loading (sanity check)...\\n\")\n\n# Test VIL from each year that has data\nfor year in years_to_check:\n    if year in data_status and 'vil' in data_status[year]:\n        year_status = data_status[year]['vil']\n        \n        if year_status['exists'] and year_status['files'] > 0:\n            mod_path = f\"{SEVIR_ROOT}/vil/{year}\"\n            files = sorted(glob.glob(f\"{mod_path}/*.h5\"))\n\n            if files:\n                test_file = files[0]\n                print(f\"Testing VIL ({year}): {os.path.basename(test_file)}\")\n\n                try:\n                    with h5py.File(test_file, 'r') as h5:\n                        # Check structure\n                        print(f\"  Keys: {list(h5.keys())[:5]}...\")  # Show first 5 keys\n\n                        if 'vil' in h5:\n                            data = h5['vil']\n                            print(f\"  Shape: {data.shape}\")\n                            print(f\"  Dtype: {data.dtype}\")\n\n                            # Load first sample\n                            sample = data[0]\n                            print(f\"  Sample shape: {sample.shape}\")\n                            print(f\"  Sample range: [{sample.min():.1f}, {sample.max():.1f}]\")\n                            print(f\"  ‚úÖ File loads correctly\\n\")\n                except Exception as e:\n                    print(f\"  ‚ùå Error loading file: {e}\\n\")\n        else:\n            print(f\"‚è≠Ô∏è  No VIL files for {year}\\n\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "potKGPcKNlXp"
   },
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**What we checked:**\n",
    "- Which SEVIR modalities exist\n",
    "- File counts and sizes\n",
    "- Catalog completeness\n",
    "- File integrity\n",
    "\n",
    "**Next steps:**\n",
    "1. If data is incomplete, set `DOWNLOAD=True` and re-run Step 5\n",
    "2. Once data is ready, proceed to `03_Test_DataLoader.ipynb`\n",
    "3. That notebook will test actually loading and processing the data"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}