{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_s4D2UuNlXn"
   },
   "source": [
    "# 02: Data Verification and Download\n",
    "\n",
    "**Purpose:** Check what SEVIR data you have and download missing files\n",
    "\n",
    "**What this does:**\n",
    "- Check which SEVIR modalities exist\n",
    "- Count files per modality\n",
    "- Identify missing data\n",
    "- Provide download instructions/scripts\n",
    "\n",
    "**What this does NOT do:**\n",
    "- Load actual data into memory\n",
    "- Create models\n",
    "- Run training\n",
    "\n",
    "**Expected time:** 5 minutes (or 30-90 min if downloading data)\n",
    "\n",
    "---\n",
    "\n",
    "**Prerequisites:** Run `01_Setup_and_Environment.ipynb` first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_O58iWnNlXo"
   },
   "source": [
    "## Step 1: Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5sGys8tNlXo",
    "outputId": "30f7c35e-63dd-459b-d1da-93a8e505cb0b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": "import os\nimport glob\nimport pandas as pd\n\n# Your data directory (should match from 01_Setup)\nDRIVE_ROOT = \"/content/drive/MyDrive/SEVIR_Data\"\nSEVIR_ROOT = f\"{DRIVE_ROOT}/data/sevir\"\nCATALOG_PATH = f\"{DRIVE_ROOT}/data/SEVIR_CATALOG.csv\"\n\nprint(f\"SEVIR root: {SEVIR_ROOT}\")\nprint(f\"Catalog: {CATALOG_PATH}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7AIQjCyNlXo"
   },
   "source": [
    "## Step 2: Check What Data Files Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edgrK2WONlXp"
   },
   "outputs": [],
   "source": "print(\"=\"*70)\nprint(\"SEVIR DATA CHECK\")\nprint(\"=\"*70)\n\nmodalities = {\n    'vil': 'VIL (Radar) - TARGET MODALITY',\n    'ir069': 'GOES-16 C09 (Water Vapor 6.9Œºm)',\n    'ir107': 'GOES-16 C13 (IR Window 10.7Œºm)',\n    'lght': 'GOES-16 GLM (Lightning)'\n}\n\ndata_status = {}\n\nfor mod, desc in modalities.items():\n    mod_path = f\"{SEVIR_ROOT}/{mod}/2019\"\n    \n    if os.path.exists(mod_path):\n        h5_files = glob.glob(f\"{mod_path}/*.h5\")\n        total_gb = sum(os.path.getsize(f) for f in h5_files) / 1e9\n        \n        # Expected: ~174 files per modality for full dataset\n        status = \"‚úÖ\" if len(h5_files) >= 100 else (\"‚ö†Ô∏è\" if len(h5_files) > 0 else \"‚ùå\")\n        \n        print(f\"\\n{status} {mod.upper():8s} - {desc}\")\n        print(f\"   Path: {mod_path}\")\n        print(f\"   Files: {len(h5_files):3d} / ~174 expected\")\n        print(f\"   Size: {total_gb:.1f} GB\")\n        \n        data_status[mod] = {\n            'exists': True,\n            'files': len(h5_files),\n            'complete': len(h5_files) >= 100\n        }\n    else:\n        print(f\"\\n‚ùå {mod.upper():8s} - {desc}\")\n        print(f\"   MISSING: {mod_path}\")\n        \n        data_status[mod] = {\n            'exists': False,\n            'files': 0,\n            'complete': False\n        }\n\nprint(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT8FiAALNlXp"
   },
   "source": [
    "## Step 3: Check Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNzLBzfUNlXp"
   },
   "outputs": [],
   "source": "# Load catalog if it exists\nif os.path.exists(CATALOG_PATH):\n    catalog = pd.read_csv(CATALOG_PATH, low_memory=False)\n    \n    print(\"üìã SEVIR Catalog Analysis\\n\")\n    \n    for mod in ['vil', 'ir069', 'ir107', 'lght']:\n        mod_catalog = catalog[catalog['img_type'] == mod]\n        unique_files = mod_catalog['file_name'].nunique()\n        unique_events = mod_catalog['id'].nunique()\n        \n        print(f\"{mod.upper():8s}:\")\n        print(f\"  Catalog lists {unique_files} files\")\n        print(f\"  Catalog lists {unique_events} events\")\n        \n        if data_status[mod]['exists']:\n            actual_files = data_status[mod]['files']\n            coverage = (actual_files / unique_files * 100) if unique_files > 0 else 0\n            print(f\"  You have {actual_files} files ({coverage:.1f}% coverage)\")\n        print()\nelse:\n    print(f\"‚ùå Catalog not found: {CATALOG_PATH}\")\n    print(\"   Download from: https://sevir.mit.edu/\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPhwpEvfNlXp"
   },
   "source": [
    "## Step 4: Data Completeness Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSXACt0hNlXp"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DATA COMPLETENESS ASSESSMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if we have enough data\n",
    "vil_complete = data_status['vil']['complete']\n",
    "all_complete = all(status['complete'] for status in data_status.values())\n",
    "\n",
    "if all_complete:\n",
    "    print(\"\\n‚úÖ EXCELLENT: All modalities complete!\")\n",
    "    print(\"   Ready for full multimodal training\")\n",
    "    need_download = False\n",
    "\n",
    "elif vil_complete:\n",
    "    print(\"\\n‚ö†Ô∏è  PARTIAL: VIL complete, but other modalities incomplete\")\n",
    "    print(\"   Can train, but model will use zeros for missing modalities\")\n",
    "    print(\"   Performance will be degraded\")\n",
    "    print(\"   \\n   Recommendation: Download all modalities for best results\")\n",
    "    need_download = True\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ùå INCOMPLETE: VIL data missing or incomplete\")\n",
    "    print(\"   VIL is the TARGET modality - training will fail without it\")\n",
    "    print(\"   \\n   Action Required: Download VIL data (critical)\")\n",
    "    need_download = True\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeqQNEg4NlXp"
   },
   "source": [
    "## Step 5: Download Data (If Needed)\n",
    "\n",
    "**Set `DOWNLOAD = True` to enable download**\n",
    "\n",
    "**WARNING:** This will download ~50 GB and take 30-90 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lp90exmoNlXp"
   },
   "outputs": [],
   "source": "DOWNLOAD = False  # ‚ö†Ô∏è SET TO True TO DOWNLOAD\n\nif DOWNLOAD and need_download:\n    print(\"=\"*70)\n    print(\"DOWNLOADING SEVIR DATA FROM AWS S3\")\n    print(\"=\"*70)\n    \n    # Install AWS CLI\n    !pip install -q awscli\n    \n    # Download each modality\n    download_info = {\n        'vil': ('~25 GB', '15-45 min', 'CRITICAL - TARGET MODALITY'),\n        'ir069': ('~9 GB', '5-15 min', 'Water vapor channel'),\n        'ir107': ('~9 GB', '5-15 min', 'IR window channel'),\n        'lght': ('~6 GB', '5-15 min', 'Lightning data')\n    }\n    \n    for mod, (size, time, desc) in download_info.items():\n        if not data_status[mod]['complete']:\n            print(f\"\\n{'='*70}\")\n            print(f\"Downloading {mod.upper()} - {desc}\")\n            print(f\"Size: {size}, Time: {time}\")\n            print(f\"{'='*70}\")\n            \n            target_dir = f\"{SEVIR_ROOT}/{mod}/2019\"\n            !mkdir -p {target_dir}\n            !aws s3 sync s3://sevir/data/{mod}/2019/ {target_dir} --no-sign-request --region us-east-1\n            \n            # Verify\n            files = glob.glob(f\"{target_dir}/*.h5\")\n            print(f\"\\n‚úÖ Downloaded {len(files)} files for {mod}\")\n        else:\n            print(f\"\\n‚úÖ {mod.upper()} already complete, skipping\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"‚úÖ DOWNLOAD COMPLETE\")\n    print(\"=\"*70)\n    print(\"\\nRe-run Step 2 to verify all files downloaded correctly\")\n    \nelif not DOWNLOAD:\n    print(\"‚è≠Ô∏è  Download skipped (set DOWNLOAD=True to enable)\")\n    if need_download:\n        print(\"\\n‚ö†Ô∏è  WARNING: You need more data for full training\")\n        print(\"   Set DOWNLOAD=True above and re-run this cell\")\nelse:\n    print(\"‚úÖ Data already complete, no download needed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXhOBfrbNlXp"
   },
   "source": [
    "## Step 6: Sample a Few Files (Sanity Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cie1oh20NlXp"
   },
   "outputs": [],
   "source": "import h5py\nimport numpy as np\n\nprint(\"Testing file loading (sanity check)...\\n\")\n\nfor mod in ['vil']:\n    if data_status[mod]['exists'] and data_status[mod]['files'] > 0:\n        # Get first file\n        mod_path = f\"{SEVIR_ROOT}/{mod}/2019\"\n        files = sorted(glob.glob(f\"{mod_path}/*.h5\"))\n        \n        if files:\n            test_file = files[0]\n            print(f\"Testing {mod.upper()}: {os.path.basename(test_file)}\")\n            \n            try:\n                with h5py.File(test_file, 'r') as h5:\n                    # Check structure\n                    print(f\"  Keys: {list(h5.keys())}\")\n                    \n                    if mod in h5:\n                        data = h5[mod]\n                        print(f\"  Shape: {data.shape}\")\n                        print(f\"  Dtype: {data.dtype}\")\n                        \n                        # Load first sample\n                        sample = data[0]\n                        print(f\"  Sample shape: {sample.shape}\")\n                        print(f\"  Sample range: [{sample.min():.1f}, {sample.max():.1f}]\")\n                        print(f\"  ‚úÖ File loads correctly\\n\")\n            except Exception as e:\n                print(f\"  ‚ùå Error loading file: {e}\\n\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "potKGPcKNlXp"
   },
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**What we checked:**\n",
    "- Which SEVIR modalities exist\n",
    "- File counts and sizes\n",
    "- Catalog completeness\n",
    "- File integrity\n",
    "\n",
    "**Next steps:**\n",
    "1. If data is incomplete, set `DOWNLOAD=True` and re-run Step 5\n",
    "2. Once data is ready, proceed to `03_Test_DataLoader.ipynb`\n",
    "3. That notebook will test actually loading and processing the data"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}