{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_s4D2UuNlXn"
   },
   "source": [
    "# 02: Data Verification and Download\n",
    "\n",
    "**Purpose:** Check what SEVIR data you have and download missing files\n",
    "\n",
    "**What this does:**\n",
    "- Check which SEVIR modalities exist\n",
    "- Count files per modality\n",
    "- Identify missing data\n",
    "- Provide download instructions/scripts\n",
    "\n",
    "**What this does NOT do:**\n",
    "- Load actual data into memory\n",
    "- Create models\n",
    "- Run training\n",
    "\n",
    "**Expected time:** 5 minutes (or 30-90 min if downloading data)\n",
    "\n",
    "---\n",
    "\n",
    "**Prerequisites:** Run `01_Setup_and_Environment.ipynb` first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_O58iWnNlXo"
   },
   "source": [
    "## Step 1: Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5sGys8tNlXo",
    "outputId": "7cefd5ad-02e5-4dd5-c85c-09444e7ccd1e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": "from google.colab import drive\nimport os\nimport glob\nimport pandas as pd\n\n# Mount Google Drive FIRST\nprint(\"Mounting Google Drive...\")\ndrive.mount('/content/drive', force_remount=False)\nprint(\"‚úÖ Drive mounted\\n\")\n\n# Your data directory (should match from 01_Setup)\nDRIVE_ROOT = \"/content/drive/MyDrive/SEVIR_Data\"\nSEVIR_ROOT = f\"{DRIVE_ROOT}/data/sevir\"\nCATALOG_PATH = f\"{DRIVE_ROOT}/data/SEVIR_CATALOG.csv\"\n\nprint(f\"SEVIR root: {SEVIR_ROOT}\")\nprint(f\"Catalog: {CATALOG_PATH}\")\n\n# Verify paths exist\nprint(f\"\\nVerifying paths...\")\nprint(f\"SEVIR_Data exists: {os.path.exists(DRIVE_ROOT)}\")\nprint(f\"sevir folder exists: {os.path.exists(SEVIR_ROOT)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7AIQjCyNlXo"
   },
   "source": [
    "## Step 2: Check What Data Files Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "edgrK2WONlXp",
    "outputId": "7c1aa526-abb5-4918-bbaf-4cebb619d2aa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "SEVIR DATA CHECK\n",
      "======================================================================\n",
      "\n",
      "‚ùå VIL      - VIL (Radar) - TARGET MODALITY\n",
      "   MISSING: /content/drive/MyDrive/SEVIR_Data/data/sevir/vil/2019\n",
      "\n",
      "‚ùå IR069    - GOES-16 C09 (Water Vapor 6.9Œºm)\n",
      "   MISSING: /content/drive/MyDrive/SEVIR_Data/data/sevir/ir069/2019\n",
      "\n",
      "‚ùå IR107    - GOES-16 C13 (IR Window 10.7Œºm)\n",
      "   MISSING: /content/drive/MyDrive/SEVIR_Data/data/sevir/ir107/2019\n",
      "\n",
      "‚ùå LGHT     - GOES-16 GLM (Lightning)\n",
      "   MISSING: /content/drive/MyDrive/SEVIR_Data/data/sevir/lght/2019\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SEVIR DATA CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "modalities = {\n",
    "    'vil': 'VIL (Radar) - TARGET MODALITY',\n",
    "    'ir069': 'GOES-16 C09 (Water Vapor 6.9Œºm)',\n",
    "    'ir107': 'GOES-16 C13 (IR Window 10.7Œºm)',\n",
    "    'lght': 'GOES-16 GLM (Lightning)'\n",
    "}\n",
    "\n",
    "data_status = {}\n",
    "\n",
    "for mod, desc in modalities.items():\n",
    "    mod_path = f\"{SEVIR_ROOT}/{mod}/2019\"\n",
    "\n",
    "    if os.path.exists(mod_path):\n",
    "        h5_files = glob.glob(f\"{mod_path}/*.h5\")\n",
    "        total_gb = sum(os.path.getsize(f) for f in h5_files) / 1e9\n",
    "\n",
    "        # Expected: ~174 files per modality for full dataset\n",
    "        status = \"‚úÖ\" if len(h5_files) >= 100 else (\"‚ö†Ô∏è\" if len(h5_files) > 0 else \"‚ùå\")\n",
    "\n",
    "        print(f\"\\n{status} {mod.upper():8s} - {desc}\")\n",
    "        print(f\"   Path: {mod_path}\")\n",
    "        print(f\"   Files: {len(h5_files):3d} / ~174 expected\")\n",
    "        print(f\"   Size: {total_gb:.1f} GB\")\n",
    "\n",
    "        data_status[mod] = {\n",
    "            'exists': True,\n",
    "            'files': len(h5_files),\n",
    "            'complete': len(h5_files) >= 100\n",
    "        }\n",
    "    else:\n",
    "        print(f\"\\n‚ùå {mod.upper():8s} - {desc}\")\n",
    "        print(f\"   MISSING: {mod_path}\")\n",
    "\n",
    "        data_status[mod] = {\n",
    "            'exists': False,\n",
    "            'files': 0,\n",
    "            'complete': False\n",
    "        }\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT8FiAALNlXp"
   },
   "source": [
    "## Step 3: Check Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mNzLBzfUNlXp",
    "outputId": "786dc08b-4205-4486-f729-9f0b5a10345a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚ùå Catalog not found: /content/drive/MyDrive/SEVIR_Data/data/SEVIR_CATALOG.csv\n",
      "   Download from: https://sevir.mit.edu/\n"
     ]
    }
   ],
   "source": [
    "# Load catalog if it exists\n",
    "if os.path.exists(CATALOG_PATH):\n",
    "    catalog = pd.read_csv(CATALOG_PATH, low_memory=False)\n",
    "\n",
    "    print(\"üìã SEVIR Catalog Analysis\\n\")\n",
    "\n",
    "    for mod in ['vil', 'ir069', 'ir107', 'lght']:\n",
    "        mod_catalog = catalog[catalog['img_type'] == mod]\n",
    "        unique_files = mod_catalog['file_name'].nunique()\n",
    "        unique_events = mod_catalog['id'].nunique()\n",
    "\n",
    "        print(f\"{mod.upper():8s}:\")\n",
    "        print(f\"  Catalog lists {unique_files} files\")\n",
    "        print(f\"  Catalog lists {unique_events} events\")\n",
    "\n",
    "        if data_status[mod]['exists']:\n",
    "            actual_files = data_status[mod]['files']\n",
    "            coverage = (actual_files / unique_files * 100) if unique_files > 0 else 0\n",
    "            print(f\"  You have {actual_files} files ({coverage:.1f}% coverage)\")\n",
    "        print()\n",
    "else:\n",
    "    print(f\"‚ùå Catalog not found: {CATALOG_PATH}\")\n",
    "    print(\"   Download from: https://sevir.mit.edu/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPhwpEvfNlXp"
   },
   "source": [
    "## Step 4: Data Completeness Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nSXACt0hNlXp",
    "outputId": "87dd9785-7423-4b6a-840f-844701779899",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "DATA COMPLETENESS ASSESSMENT\n",
      "======================================================================\n",
      "\n",
      "‚ùå INCOMPLETE: VIL data missing or incomplete\n",
      "   VIL is the TARGET modality - training will fail without it\n",
      "   \n",
      "   Action Required: Download VIL data (critical)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DATA COMPLETENESS ASSESSMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if we have enough data\n",
    "vil_complete = data_status['vil']['complete']\n",
    "all_complete = all(status['complete'] for status in data_status.values())\n",
    "\n",
    "if all_complete:\n",
    "    print(\"\\n‚úÖ EXCELLENT: All modalities complete!\")\n",
    "    print(\"   Ready for full multimodal training\")\n",
    "    need_download = False\n",
    "\n",
    "elif vil_complete:\n",
    "    print(\"\\n‚ö†Ô∏è  PARTIAL: VIL complete, but other modalities incomplete\")\n",
    "    print(\"   Can train, but model will use zeros for missing modalities\")\n",
    "    print(\"   Performance will be degraded\")\n",
    "    print(\"   \\n   Recommendation: Download all modalities for best results\")\n",
    "    need_download = True\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ùå INCOMPLETE: VIL data missing or incomplete\")\n",
    "    print(\"   VIL is the TARGET modality - training will fail without it\")\n",
    "    print(\"   \\n   Action Required: Download VIL data (critical)\")\n",
    "    need_download = True\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeqQNEg4NlXp"
   },
   "source": [
    "## Step 5: Download Data (If Needed)\n",
    "\n",
    "**Set `DOWNLOAD = True` to enable download**\n",
    "\n",
    "**WARNING:** This will download ~50 GB and take 30-90 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lp90exmoNlXp"
   },
   "outputs": [],
   "source": "DOWNLOAD = False  # ‚ö†Ô∏è SET TO True TO DOWNLOAD\n\nif DOWNLOAD and need_download:\n    print(\"=\"*70)\n    print(\"DOWNLOADING SEVIR DATA FROM AWS S3\")\n    print(\"=\"*70)\n    \n    # Install AWS CLI\n    !pip install -q awscli\n    \n    # Download each modality\n    download_info = {\n        'vil': ('~25 GB', '15-45 min', 'CRITICAL - TARGET MODALITY'),\n        'ir069': ('~9 GB', '5-15 min', 'Water vapor channel'),\n        'ir107': ('~9 GB', '5-15 min', 'IR window channel'),\n        'lght': ('~6 GB', '5-15 min', 'Lightning data')\n    }\n    \n    for mod, (size, time, desc) in download_info.items():\n        if not data_status[mod]['complete']:\n            print(f\"\\n{'='*70}\")\n            print(f\"Downloading {mod.upper()} - {desc}\")\n            print(f\"Size: {size}, Time: {time}\")\n            print(f\"{'='*70}\")\n            \n            target_dir = f\"{SEVIR_ROOT}/{mod}/2019\"\n            \n            # Create directory\n            !mkdir -p \"{target_dir}\"\n            \n            # First, let's check what's available in S3\n            print(f\"\\nüìã Checking S3 bucket contents...\")\n            !aws s3 ls s3://sevir/data/{mod}/2019/ --no-sign-request | head -10\n            \n            # Count how many files are in S3\n            import subprocess\n            result = subprocess.run(\n                f'aws s3 ls s3://sevir/data/{mod}/2019/ --no-sign-request | wc -l',\n                shell=True,\n                capture_output=True,\n                text=True\n            )\n            s3_file_count = result.stdout.strip()\n            print(f\"üì¶ Found {s3_file_count} files in S3 for {mod}\")\n            \n            # Download with sync\n            print(f\"\\n‚¨áÔ∏è  Starting download...\")\n            !aws s3 sync s3://sevir/data/{mod}/2019/ \"{target_dir}\" --no-sign-request --region us-east-1\n            \n            # Verify what we have now\n            files = glob.glob(f\"{target_dir}/*.h5\")\n            print(f\"\\n‚úÖ Now have {len(files)} files for {mod}\")\n        else:\n            print(f\"\\n‚úÖ {mod.upper()} already complete, skipping\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"‚úÖ DOWNLOAD COMPLETE\")\n    print(\"=\"*70)\n    print(\"\\nRe-run Step 2 to verify all files downloaded correctly\")\n    \nelif not DOWNLOAD:\n    print(\"‚è≠Ô∏è  Download skipped (set DOWNLOAD=True to enable)\")\n    if need_download:\n        print(\"\\n‚ö†Ô∏è  WARNING: You need more data for full training\")\n        print(\"   Set DOWNLOAD=True above and re-run this cell\")\nelse:\n    print(\"‚úÖ Data already complete, no download needed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXhOBfrbNlXp"
   },
   "source": [
    "## Step 6: Sample a Few Files (Sanity Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cie1oh20NlXp"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "print(\"Testing file loading (sanity check)...\\n\")\n",
    "\n",
    "for mod in ['vil']:\n",
    "    if data_status[mod]['exists'] and data_status[mod]['files'] > 0:\n",
    "        # Get first file\n",
    "        mod_path = f\"{SEVIR_ROOT}/{mod}/2019\"\n",
    "        files = sorted(glob.glob(f\"{mod_path}/*.h5\"))\n",
    "\n",
    "        if files:\n",
    "            test_file = files[0]\n",
    "            print(f\"Testing {mod.upper()}: {os.path.basename(test_file)}\")\n",
    "\n",
    "            try:\n",
    "                with h5py.File(test_file, 'r') as h5:\n",
    "                    # Check structure\n",
    "                    print(f\"  Keys: {list(h5.keys())}\")\n",
    "\n",
    "                    if mod in h5:\n",
    "                        data = h5[mod]\n",
    "                        print(f\"  Shape: {data.shape}\")\n",
    "                        print(f\"  Dtype: {data.dtype}\")\n",
    "\n",
    "                        # Load first sample\n",
    "                        sample = data[0]\n",
    "                        print(f\"  Sample shape: {sample.shape}\")\n",
    "                        print(f\"  Sample range: [{sample.min():.1f}, {sample.max():.1f}]\")\n",
    "                        print(f\"  ‚úÖ File loads correctly\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Error loading file: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "potKGPcKNlXp"
   },
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**What we checked:**\n",
    "- Which SEVIR modalities exist\n",
    "- File counts and sizes\n",
    "- Catalog completeness\n",
    "- File integrity\n",
    "\n",
    "**Next steps:**\n",
    "1. If data is incomplete, set `DOWNLOAD=True` and re-run Step 5\n",
    "2. Once data is ready, proceed to `03_Test_DataLoader.ipynb`\n",
    "3. That notebook will test actually loading and processing the data"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}